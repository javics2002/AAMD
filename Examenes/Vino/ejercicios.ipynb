{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79756688",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del perceptrón: 87.58%\n",
      "Matriz de confusión:\n",
      " [[893  32]\n",
      " [101  45]]\n",
      "Error cuadratico medio: 0.12 \n",
      "\n",
      "Precisión del perceptrón: 88.83%\n",
      "Matriz de confusión:\n",
      " [[444  13]\n",
      " [ 46  25]]\n",
      "Error cuadratico medio: 0.11 \n",
      "\n",
      "------------------------------\n",
      "\n",
      "DATOS DEL SUPPORT VECTOR MACHINE (SVM)\n",
      "\n",
      "Precisión del SVM: 84.47%\n",
      "Matriz de confusión:\n",
      " [[421  36]\n",
      " [ 46  25]]\n",
      "Error cuadrático medio: 0.16 \n",
      "\n",
      "Scores de Validación Cruzada: [0.80930233 0.86448598 0.78971963 0.80373832 0.84579439]\n",
      "Promedio de Validación Cruzada: 0.822608128667681\n"
     ]
    }
   ],
   "source": [
    "from ann import cost, cost_regL2, backprop, backprop2, predict, feedForward\n",
    "from utils import checkNNGradients\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.io import loadmat, savemat\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, mean_squared_error\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "testData = pd.read_csv(\"winequality-test.txt\", sep=',', header=None)\n",
    "trainData = pd.read_csv(\"winequality-train.txt\", sep=',', header=None)\n",
    "\n",
    "X_train = trainData.iloc[:, :-1]\n",
    "y_train = trainData.iloc[:, -1:]\n",
    "\n",
    "y_test = testData.iloc[:, -1:]\n",
    "X_test = testData.iloc[:, :-1]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Ajustar y transformar los datos\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.25, random_state=8)\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "\n",
    "layer_sizes = [X_train.shape[1], 100, y_train.shape[1]]\n",
    "epsilon = 0.12\n",
    "theta_list = []\n",
    "\n",
    "for i in range(len(layer_sizes) - 1):\n",
    "    theta_list.append(np.random.rand(layer_sizes[i + 1], layer_sizes[i] + 1) * 2 * epsilon - epsilon)\n",
    "\n",
    "iterations = 1000\n",
    "lambda_ = 1\n",
    "alpha = 0.1\n",
    "\n",
    "for i in range(iterations):\n",
    "    cost, grads = backprop(theta_list, X_train, y_train, lambda_)\n",
    "\n",
    "    for j in range(len(theta_list)):\n",
    "        theta_list[j] -= alpha * grads[j]\n",
    "\n",
    "predictions = predict(theta_list, X_train)\n",
    "\n",
    "# Datos entrenamiento\n",
    "accuracy = accuracy_score(np.argmax(y_train, axis=1), predictions)\n",
    "print(f'Precisión del perceptrón: {accuracy * 100:.2f}%')\n",
    "\n",
    "conf_matrix = confusion_matrix(np.argmax(y_train, axis=1), predictions)\n",
    "print(f'Matriz de confusión:\\n {conf_matrix}')\n",
    "\n",
    "mse = mean_squared_error(np.argmax(y_train, axis=1), predictions)\n",
    "print(f'Error cuadratico medio: {mse:.2f} \\n')\n",
    "\n",
    "# Datos reales\n",
    "predictions = predict(theta_list, X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f'Precisión del perceptrón: {accuracy * 100:.2f}%')\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "print(f'Matriz de confusión:\\n {conf_matrix}')\n",
    "\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(f'Error cuadratico medio: {mse:.2f} \\n')\n",
    "\n",
    "\n",
    "# report_sklearn = classification_report(y_test, predictions)\n",
    "# print(report_sklearn)\n",
    "\n",
    "# print(\"\\nExplicaciones:\")\n",
    "# print(\"Precision: Es la proporción de instancias clasificadas como positivas que son realmente positivas.\")\n",
    "# print(\"Recall: Es la proporción de instancias positivas que fueron correctamente clasificadas como positivas.\")\n",
    "# print(\"F1-score: Es la media armónica ponderada de precision y recall. Es útil cuando hay desbalance de clases.\")\n",
    "# print(\"Support: Es el número real de ocurrencias de la clase en el conjunto de prueba.\")\n",
    "# print(\"Accuracy: Es la proporción de instancias correctamente clasificadas en el conjunto de prueba.\")\n",
    "# print(\"Macro avg: Es el promedio no ponderado de precision, recall y f1-score para todas las clases.\")\n",
    "# print(\"Weighted avg: Es el promedio ponderado por el soporte (número de instancias) de precision, recall y f1-score.\")\n",
    "\n",
    "# SVM\n",
    "print('------------------------------\\n')\n",
    "print('DATOS DEL SUPPORT VECTOR MACHINE (SVM)\\n')\n",
    "\n",
    "svm_classifier = SVC(kernel='sigmoid', C=1.0)\n",
    "svm_classifier.fit(X_train, np.argmax(y_train, axis=1))\n",
    "\n",
    "# Datos de test\n",
    "predictions = svm_classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f'Precisión del SVM: {accuracy * 100:.2f}%')\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "print(f'Matriz de confusión:\\n {conf_matrix}')\n",
    "\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(f'Error cuadrático medio: {mse:.2f} \\n')\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Entrenar modelo con validación cruzada\n",
    "scores = cross_val_score(svm_classifier, X_train, np.argmax(y_train, axis=1), cv=5)  # cv es el número de particiones\n",
    "\n",
    "# Imprimir los scores de cada iteración de validación cruzada\n",
    "print(\"Scores de Validación Cruzada:\", scores)\n",
    "print(\"Promedio de Validación Cruzada:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd4a418",
   "metadata": {},
   "source": [
    "### Teoria\n",
    "\n",
    "Justificar los datos del perceptron respecto a SVM\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
