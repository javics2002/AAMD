{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79756688",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del perceptrón: 86.37%\n",
      "Matriz de confusión:\n",
      " [[925   0]\n",
      " [146   0]]\n",
      "Error cuadratico medio: 0.14 \n",
      "\n",
      "Precisión del perceptrón: 86.55%\n",
      "Matriz de confusión:\n",
      " [[457   0]\n",
      " [ 71   0]]\n",
      "Error cuadratico medio: 0.13 \n",
      "\n",
      "------------------------------\n",
      "\n",
      "DATOS DEL SUPPORT VECTOR MACHINE (SVM)\n",
      "\n",
      "Precisión del SVM: 86.55%\n",
      "Matriz de confusión:\n",
      " [[457   0]\n",
      " [ 71   0]]\n",
      "Error cuadrático medio: 0.13 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ann import cost, cost_regL2, backprop, backprop2, predict, feedForward\n",
    "from utils import checkNNGradients\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.io import loadmat, savemat\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, mean_squared_error\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "testData = pd.read_csv(\"winequality-test.txt\")\n",
    "trainData = pd.read_csv(\"winequality-train.txt\")\n",
    "\n",
    "X_train = trainData.iloc[:, :-1]\n",
    "y_train = trainData.iloc[:, -1:]\n",
    "\n",
    "y_test = testData.iloc[:, -1:]\n",
    "X_test = testData.iloc[:, :-1]\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "\n",
    "layer_sizes = [X_train.shape[1], 100, y_train.shape[1]]\n",
    "epsilon = 0.12\n",
    "theta_list = []\n",
    "\n",
    "for i in range(len(layer_sizes) - 1):\n",
    "    theta_list.append(np.random.rand(layer_sizes[i + 1], layer_sizes[i] + 1) * 2 * epsilon - epsilon)\n",
    "\n",
    "iterations = 1000\n",
    "lambda_ = 1\n",
    "alpha = 0.1\n",
    "\n",
    "for i in range(iterations):\n",
    "    cost, grads = backprop(theta_list, X_train, y_train, lambda_)\n",
    "\n",
    "    for j in range(len(theta_list)):\n",
    "        theta_list[j] -= alpha * grads[j]\n",
    "\n",
    "predictions = predict(theta_list, X_train)\n",
    "\n",
    "# Datos entrenamiento\n",
    "accuracy = accuracy_score(np.argmax(y_train, axis=1), predictions)\n",
    "print(f'Precisión del perceptrón: {accuracy * 100:.2f}%')\n",
    "\n",
    "conf_matrix = confusion_matrix(np.argmax(y_train, axis=1), predictions)\n",
    "print(f'Matriz de confusión:\\n {conf_matrix}')\n",
    "\n",
    "mse = mean_squared_error(np.argmax(y_train, axis=1), predictions)\n",
    "print(f'Error cuadratico medio: {mse:.2f} \\n')\n",
    "\n",
    "# Datos reales\n",
    "predictions = predict(theta_list, X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f'Precisión del perceptrón: {accuracy * 100:.2f}%')\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "print(f'Matriz de confusión:\\n {conf_matrix}')\n",
    "\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(f'Error cuadratico medio: {mse:.2f} \\n')\n",
    "\n",
    "# report_sklearn = classification_report(y_test, predictions)\n",
    "# print(report_sklearn)\n",
    "\n",
    "# print(\"\\nExplicaciones:\")\n",
    "# print(\"Precision: Es la proporción de instancias clasificadas como positivas que son realmente positivas.\")\n",
    "# print(\"Recall: Es la proporción de instancias positivas que fueron correctamente clasificadas como positivas.\")\n",
    "# print(\"F1-score: Es la media armónica ponderada de precision y recall. Es útil cuando hay desbalance de clases.\")\n",
    "# print(\"Support: Es el número real de ocurrencias de la clase en el conjunto de prueba.\")\n",
    "# print(\"Accuracy: Es la proporción de instancias correctamente clasificadas en el conjunto de prueba.\")\n",
    "# print(\"Macro avg: Es el promedio no ponderado de precision, recall y f1-score para todas las clases.\")\n",
    "# print(\"Weighted avg: Es el promedio ponderado por el soporte (número de instancias) de precision, recall y f1-score.\")\n",
    "\n",
    "# SVM\n",
    "print('------------------------------\\n')\n",
    "print('DATOS DEL SUPPORT VECTOR MACHINE (SVM)\\n')\n",
    "\n",
    "svm_classifier = SVC(kernel='linear', C=1.0)\n",
    "svm_classifier.fit(X_train, np.argmax(y_train, axis=1))\n",
    "\n",
    "# Datos de test\n",
    "predictions = svm_classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f'Precisión del SVM: {accuracy * 100:.2f}%')\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "print(f'Matriz de confusión:\\n {conf_matrix}')\n",
    "\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(f'Error cuadrático medio: {mse:.2f} \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd4a418",
   "metadata": {},
   "source": [
    "### Teoria\n",
    "\n",
    "Justificar los datos del perceptron respecto a SVM\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
