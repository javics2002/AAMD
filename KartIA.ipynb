{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0565b8dc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmpl_toolkits\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmplot3d\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Axes3D\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexpress\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpx\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from RedNeu import cost, backprop , predict,initialize_parameters,update_parameters\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import plotly.express as px\n",
    "from sklearn.preprocessing import MinMaxScaler,OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix, mean_squared_error\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV,StratifiedKFold\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from Utils import ExportAllformatsMLPSKlearn,export_knn_for_unity\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('KartDataset.csv')\n",
    "print(df.head())\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "################ Representacion Grafica\n",
    "# Visualización de gráfico 3D para tres atributos específicos\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(df['ray2'], df['kartx'], df['time'], c=df['action'].astype('category').cat.codes, cmap='viridis', s=50)\n",
    "ax.set_xlabel('Ray2')\n",
    "ax.set_ylabel('KartX')\n",
    "ax.set_zlabel('Time')\n",
    "ax.set_title('Gráfico 3D de Tres Atributos con Colores por Clase')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Visualización de gráfico de pares para todos los atributos\n",
    "fig = px.scatter_matrix(\n",
    "    df,\n",
    "    dimensions=['ray1', 'ray2', 'ray3', 'ray4', 'ray5', 'kartx', 'karty', 'kartz', 'time'],\n",
    "    color='action',\n",
    "    title='Gráfico de Pares para Explorar Relaciones',\n",
    ")\n",
    "fig.update_traces(diagonal_visible=False)  # No mostrar histogramas en la diagonal\n",
    "fig.show()\n",
    "\n",
    "# Visualización de gráfico de dispersión 3D con variación en el tiempo\n",
    "fig_3d = px.scatter_3d(\n",
    "    df,\n",
    "    x='kartx',\n",
    "    y='karty',\n",
    "    z='kartz',\n",
    "    color='action',\n",
    "    title='Gráfico de Dispersión 3D con Variación en el Tiempo',\n",
    ")\n",
    "fig_3d.show()\n",
    "#####################################################\n",
    "\n",
    "\n",
    "\n",
    "##NORMALIZAR DATOS CON MINMAXSCALER\n",
    "scaler = MinMaxScaler()\n",
    "df[['ray1', 'ray2', 'ray3', 'kartx', 'karty', 'kartz', 'time']] = scaler.fit_transform( df[['ray1', 'ray2', 'ray3', 'kartx', 'karty', 'kartz', 'time']]\n",
    ")\n",
    "# Verificar la versión limpia del dataset\n",
    "print(\"DataFrame después de manejar valores nulos y normalizar:\")\n",
    "print(df.head())\n",
    "\n",
    "################################# ONE HOT ENCODING REPRESENTACION VISUAL NO APLICADO AL DATA FRAME TODAVIA \n",
    "\n",
    "# Crear un codificador OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Ajustar y transformar la columna 'action' usando el encoder\n",
    "action_encoded = encoder.fit_transform(df[['action']])\n",
    "\n",
    "one_hot_columns = encoder.get_feature_names_out(['action'])\n",
    "one_hot_df = pd.DataFrame(action_encoded, columns=one_hot_columns)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=one_hot_df, ci=None)\n",
    "plt.title('Representación One-Hot Encoding de la Columna \"action\"')\n",
    "plt.xlabel('Índice de Ejemplo')\n",
    "plt.ylabel('Valor (0 o 1)')\n",
    "plt.show()\n",
    "\n",
    "################################################################## PERCEPTRON MULTICAPA CON ONE HOT ENCODING Y MIN MAX SCALER\n",
    "\n",
    "### ONE HOT ENCODING PERO APLICADO AL DATA FRAME (Previamente normaliazdo)\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "df = df.drop(['ray4','karty'], axis=1)\n",
    "\n",
    "action_encoded = encoder.fit_transform(df[['action']])\n",
    "\n",
    "df_encoded = pd.concat([df, pd.DataFrame(action_encoded, columns=encoder.get_feature_names_out(['action']))], axis=1)\n",
    "df_encoded = df_encoded.drop(['action'], axis=1)\n",
    "# Separar datos de entrada y salida\n",
    "X = df_encoded[['ray1','ray2', 'ray3', 'kartx', 'kartz', 'time']]\n",
    "Y = df_encoded[encoder.get_feature_names_out(['action'])]\n",
    "\n",
    "# Dividir el conjunto de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=15)\n",
    "\n",
    "# Paso 2: Configuración del perceptrón multicapa\n",
    "layer_sizes = [X.shape[1], 10,len(encoder.get_feature_names_out(['action']))]  # Ajusta el número de neuronas según sea necesario\n",
    "theta_list = initialize_parameters(layer_sizes)\n",
    "\n",
    "# Añadir el sesgo a los conjuntos de entrenamiento y prueba\n",
    "X_train_with_bias = np.hstack([np.ones((X_train.shape[0], 1)), X_train])\n",
    "X_test_with_bias = np.hstack([np.ones((X_test.shape[0], 1)), X_test])\n",
    "\n",
    "\n",
    "# Ajustar hiperparámetros\n",
    "lambdaValue = 1  # Experimenta con diferentes valores\n",
    "alpha = 0.75  # Experimenta con diferentes valores\n",
    "iterations = 1000  # Experimenta con diferentes valores\n",
    "\n",
    "\n",
    "# Paso 3: Entrenamiento del perceptrón multicapa\n",
    "for _ in range(iterations):\n",
    "    J, grad = backprop(theta_list, X_train_with_bias, y_train, lambdaValue)\n",
    "    # Actualizar parámetros\n",
    "    update_parameters(theta_list, grad, alpha)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "# Paso 4: Evaluación del perceptrón multicapa\n",
    "predictions_train = predict(theta_list, X_train_with_bias)\n",
    "predictions_test = predict(theta_list, X_test_with_bias)\n",
    "\n",
    "\n",
    "# Obtener las etiquetas predichas (como índices de la clase con probabilidad máxima)\n",
    "predicted_labels_train = np.argmax(predictions_train, axis=1)\n",
    "predicted_labels_test = np.argmax(predictions_test, axis=1)\n",
    "\n",
    "# Obtener las etiquetas reales\n",
    "true_labels_train = np.argmax(y_train.to_numpy(), axis=1)\n",
    "true_labels_test = np.argmax(y_test.to_numpy(), axis=1)\n",
    "\n",
    "accuracy_train = accuracy_score(true_labels_train, predicted_labels_train)\n",
    "accuracy_test = accuracy_score(true_labels_test,predicted_labels_test)\n",
    "\n",
    "# Calcular la matriz de confusión\n",
    "conf_matrix_train = confusion_matrix(true_labels_train, predicted_labels_train)\n",
    "conf_matrix_test = confusion_matrix(true_labels_test, predicted_labels_test)\n",
    "\n",
    "\n",
    "\n",
    "##USO DE LA VALIDACION CRUZADA\n",
    "\n",
    "# Definir el número de divisiones para la validación cruzada\n",
    "num_folds = 5  # Puedes ajustar este valor según sea necesario\n",
    "# Crear el objeto KFold para la validación cruzada\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=15)\n",
    "# Lista para almacenar los resultados de la validación cruzada\n",
    "cv_results = []\n",
    "\n",
    "# Lista para almacenar los resultados de la validación cruzada\n",
    "cv_results = []\n",
    "# Lista para almacenar las matrices de confusión de cada división de la validación cruzada\n",
    "confusion_matrices = []\n",
    "\n",
    "\n",
    "\n",
    "# Iterar sobre las divisiones de validación cruzada\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "    \n",
    "\n",
    "    # Añadir el sesgo a los conjuntos de entrenamiento y prueba para esta división de la validación cruzada\n",
    "    X_train_fold_with_bias = np.hstack([np.ones((X_train_fold.shape[0], 1)), X_train_fold])\n",
    "    X_val_fold_with_bias = np.hstack([np.ones((X_val_fold.shape[0], 1)), X_val_fold])\n",
    "\n",
    "    # Entrenar el perceptrón multicapa para esta división de la validación cruzada\n",
    "    for _ in range(iterations):\n",
    "        J, grad = backprop(theta_list, X_train_fold_with_bias, y_train_fold, lambdaValue)\n",
    "        # Actualizar parámetros\n",
    "        update_parameters(theta_list, grad, alpha)\n",
    "\n",
    "    # Evaluar el perceptrón multicapa en el conjunto de validación de esta división de la validación cruzada\n",
    "    predictions_val = predict(theta_list, X_val_fold_with_bias)\n",
    "    predicted_labels_val = np.argmax(predictions_val, axis=1)\n",
    "    true_labels_val = np.argmax(y_val_fold.to_numpy(), axis=1)\n",
    "    conf_matrix_val = confusion_matrix(true_labels_val, predicted_labels_val)\n",
    "    accuracy_val = accuracy_score(true_labels_val, predicted_labels_val)\n",
    "    cv_results.append(accuracy_val)\n",
    "    confusion_matrices.append(conf_matrix_val)\n",
    "\n",
    "\n",
    "\n",
    "# Calcular y mostrar la precisión promedio de la validación cruzada\n",
    "average_accuracy_cv = np.mean(cv_results)\n",
    "# Calcular la matriz de confusión promedio sobre todas las divisiones de la validación cruzada\n",
    "average_confusion_matrix = np.mean(confusion_matrices, axis=0)\n",
    "# Redondear los valores de la matriz de confusión promedio\n",
    "rounded_average_confusion_matrix = np.round(average_confusion_matrix).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "print(f'Costo de la red neuronal en entrenamiento: {cost(theta_list, X_train_with_bias, y_train.to_numpy(), lambdaValue):.2f}%')\n",
    "print(f'Precisión de entrenamiento: {accuracy_train * 100:.2f}%')\n",
    "print(f'Precisión en el conjunto de prueba: {accuracy_test * 100:.2f}%')\n",
    "print(f'Precisión promedio de los datos ded Validacion en  la Validacion Cruzada: {average_accuracy_cv * 100:.2f}%')\n",
    "# Imprimir la matriz de confusión\n",
    "print(\"Matriz de Confusión en Entrenamiento:\")\n",
    "print(conf_matrix_train)\n",
    "print(\"\\nMatriz de Confusión en Prueba:\")\n",
    "print(conf_matrix_test)\n",
    "# Imprimir la matriz de confusión promedio\n",
    "print(\"Matriz de Confusión Promedio en Validación Cruzada:\")\n",
    "print(rounded_average_confusion_matrix)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##MLP PERO DE SKLEARN CON NUESTROS VALROES DE NEURONAS , HIPERPARAMETROS E ITERACIONES\n",
    "## COMPARACION ENTRE SKLEARN (Con regresion Logistica) Y MLP Personalizado (Con regresion logistica)\n",
    "# Entrenamiento y evaluación de MLPClassifier de SKLearn\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(10),activation='logistic', alpha=alpha, max_iter=iterations, random_state=15)\n",
    "mlp_clf.fit(X_train, np.argmax(y_train.to_numpy(), axis=1))\n",
    "\n",
    "predictions_train_sklearn = mlp_clf.predict(X_train)\n",
    "accuracy_train_sklearn = accuracy_score(np.argmax(y_train.to_numpy(), axis=1), predictions_train_sklearn)\n",
    "\n",
    "predictions_test_sklearn = mlp_clf.predict(X_test)\n",
    "accuracy_test_sklearn = accuracy_score(np.argmax(y_test.to_numpy(), axis=1), predictions_test_sklearn)\n",
    "\n",
    "print('Resultados de MLPClassifier de SKLearn:')\n",
    "print(f'Precisión en entrenamiento: {accuracy_train_sklearn * 100:.2f}%')\n",
    "print(f'Precisión en prueba: {accuracy_test_sklearn * 100:.2f}%')\n",
    "\n",
    "\n",
    "\n",
    "###PRUEBA PARA VER CUAL ES LA MEJOR CONFIGURACION PARA EL MLeP Classifier de SKLearn\n",
    "\n",
    "# Dividir los datos en 1 entrenamiento, 2 validación  3 prueba/test\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, Y, test_size=0.15, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.6, random_state=42)\n",
    "\n",
    "# Escalar los datos para un mejor rendimiento del MLP\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Definir el modelo MLP\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(10), activation='relu', alpha=0.5,learning_rate='constant' ,learning_rate_init=0.01,max_iter=iterations, random_state=15)\n",
    "# Entrenar el modelo con datos de entrenamiento escalados\n",
    "mlp_clf.fit(X_train_scaled, np.argmax(y_train.to_numpy(), axis=1))\n",
    "\n",
    "\n",
    "##PASO 1 : Datos de entrenamiento \n",
    "# Evaluar el modelo en datos de entrenamiento escalados\n",
    "predictions_train_sklearn = mlp_clf.predict(X_train_scaled)\n",
    "accuracy_train_sklearn = accuracy_score(np.argmax(y_train.to_numpy(), axis=1), predictions_train_sklearn)\n",
    "conf_matrix_train = confusion_matrix(np.argmax(y_train.to_numpy(), axis=1), predictions_train_sklearn)\n",
    "mse_train_sklearn = mean_squared_error(np.argmax(y_train.to_numpy(), axis=1), predictions_train_sklearn)\n",
    "\n",
    "\n",
    "##PASO 3 : Datos de validacion (Datos no vistos) \n",
    "# Evaluar el modelo en datos de validación escalados\n",
    "predictions_val_sklearn = mlp_clf.predict(X_val_scaled)\n",
    "accuracy_val_sklearn = accuracy_score(np.argmax(y_val.to_numpy(), axis=1), predictions_val_sklearn)\n",
    "conf_matrix_val = confusion_matrix(np.argmax(y_val.to_numpy(), axis=1), predictions_val_sklearn)\n",
    "mse_val_sklearn = mean_squared_error(np.argmax(y_val.to_numpy(), axis=1), predictions_val_sklearn)\n",
    "\n",
    "##PASO 3 : Datos de prueba (Datos que son como el examen)\n",
    "# Evaluar el modelo en datos de prueba escalados\n",
    "predictions_test_sklearn = mlp_clf.predict(X_test_scaled)\n",
    "accuracy_test_sklearn = accuracy_score(np.argmax(y_test.to_numpy(), axis=1), predictions_test_sklearn)\n",
    "conf_matrix_test = confusion_matrix(np.argmax(y_test.to_numpy(), axis=1), predictions_test_sklearn)\n",
    "mse_test_sklearn = mean_squared_error(np.argmax(y_test.to_numpy(), axis=1), predictions_test_sklearn)\n",
    "\n",
    "###########################################################EXPORTACION \n",
    "# Export the model in various formats  -> AL HABER RELU LO EXPORTE COMO PUDE CON OTRE FUNCION Y AJUSTE EL TXT PARA QUE SE LEA EN UNITY \n",
    "##ExportAllformatsMLPSKlearn(mlp_clf, X_test_scaled, 'model.pkl', 'model.onnx', 'model.json', 'model_custom_format.txt')\n",
    "\n",
    "print('Resultados de MLPClassifier de SKLearn con Ajustes:')\n",
    "print(f'Precisión en entrenamiento: {accuracy_train_sklearn * 100:.2f}%')\n",
    "print(f'Precisión en prueba: {accuracy_test_sklearn * 100:.2f}%')\n",
    "print(f'Precisión en validación: {accuracy_val_sklearn * 100:.2f}%')\n",
    "print('\\n')\n",
    "print('\\n')\n",
    "\n",
    "print('Matriz de Confusión en Datos de Entrenamiento :')\n",
    "print(conf_matrix_train)\n",
    "print('Matriz de Confusión en Datos de Validación:')\n",
    "print(conf_matrix_val)\n",
    "print('Matriz de Confusión en Datos de Prueba:')\n",
    "print(conf_matrix_test)\n",
    "print(f'Error Cuadrático Medio en Datos de Entrenamiento: {mse_train_sklearn:.4f}')\n",
    "print(f'Error Cuadrático Medio en Datos de Validacion: {mse_val_sklearn:.4f}')\n",
    "print(f'Error Cuadrático Medio en Datos de Prueba: {mse_test_sklearn:.4f}')\n",
    "\n",
    "\n",
    "# Calcular la pérdida logarítmica en datos de entrenamiento\n",
    "log_loss_train = log_loss(y_train, mlp_clf.predict_proba(X_train_scaled))\n",
    "\n",
    "# Calcular la pérdida logarítmica en datos de validación\n",
    "log_loss_val = log_loss(y_val, mlp_clf.predict_proba(X_val_scaled))\n",
    "\n",
    "# Calcular la pérdida logarítmica en datos de prueba\n",
    "log_loss_test = log_loss(y_test, mlp_clf.predict_proba(X_test_scaled))\n",
    "\n",
    "print(f\"Pérdida Logarítmica en Datos de Entrenamiento: {log_loss_train:.4f}\")\n",
    "print(f\"Pérdida Logarítmica en Datos de Validación: {log_loss_val:.4f}\")\n",
    "print(f\"Pérdida Logarítmica en Datos de Prueba: {log_loss_test:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print('\\n')\n",
    "##OTRAS IMPLEMENTACIONES : RANDOM FOREST Y SVN\n",
    "#################################\n",
    "# Ahora para SVM y Random Forest\n",
    "# Dividir los datos para SVM y Random Forest de la misma manera que para MLP\n",
    "X_train_svm, X_temp_svm, y_train_svm, y_temp_svm = train_test_split(X, Y, test_size=0.15, random_state=42)\n",
    "X_val_svm, X_test_svm, y_val_svm, y_test_svm = train_test_split(X_temp_svm, y_temp_svm, test_size=0.6, random_state=42)\n",
    "\n",
    "# Escalar los datos para SVM\n",
    "X_train_scaled_svm = scaler.fit_transform(X_train_svm)\n",
    "X_val_scaled_svm = scaler.transform(X_val_svm)\n",
    "X_test_scaled_svm = scaler.transform(X_test_svm)\n",
    "\n",
    "# Definir el modelo SVM\n",
    "svm_clf = SVC(kernel='linear', C=1, random_state=42)\n",
    "# Entrenar el modelo con datos de entrenamiento escalados\n",
    "svm_clf.fit(X_train_scaled_svm, np.argmax(y_train_svm.to_numpy(), axis=1))\n",
    "\n",
    "# PASO 1: Datos de entrenamiento para SVM\n",
    "predictions_train_svm = svm_clf.predict(X_train_scaled_svm)\n",
    "accuracy_train_svm = accuracy_score(np.argmax(y_train_svm.to_numpy(), axis=1), predictions_train_svm)\n",
    "conf_matrix_train_svm = confusion_matrix(np.argmax(y_train_svm.to_numpy(), axis=1), predictions_train_svm)\n",
    "mse_train_svm = mean_squared_error(np.argmax(y_train_svm.to_numpy(), axis=1), predictions_train_svm)\n",
    "\n",
    "# PASO 2: Datos de validación para SVM\n",
    "predictions_val_svm = svm_clf.predict(X_val_scaled_svm)\n",
    "accuracy_val_svm = accuracy_score(np.argmax(y_val_svm.to_numpy(), axis=1), predictions_val_svm)\n",
    "conf_matrix_val_svm = confusion_matrix(np.argmax(y_val_svm.to_numpy(), axis=1), predictions_val_svm)\n",
    "mse_val_svm = mean_squared_error(np.argmax(y_val_svm.to_numpy(), axis=1), predictions_val_svm)\n",
    "\n",
    "# PASO 3: Datos de prueba para SVM\n",
    "predictions_test_svm = svm_clf.predict(X_test_scaled_svm)\n",
    "accuracy_test_svm = accuracy_score(np.argmax(y_test_svm.to_numpy(), axis=1), predictions_test_svm)\n",
    "conf_matrix_test_svm = confusion_matrix(np.argmax(y_test_svm.to_numpy(), axis=1), predictions_test_svm)\n",
    "mse_test_svm = mean_squared_error(np.argmax(y_test_svm.to_numpy(), axis=1), predictions_test_svm)\n",
    "print('Resultados de SVM con Ajustes:')\n",
    "print(f'Precisión en entrenamiento: {accuracy_train_svm * 100:.2f}%')\n",
    "print(f'Precisión en prueba: {accuracy_test_svm * 100:.2f}%')\n",
    "print(f'Precisión en validación: {accuracy_val_svm * 100:.2f}%')\n",
    "print('\\n')\n",
    "print('Matriz de Confusión en Datos de Entrenamiento para SVM:')\n",
    "print(conf_matrix_train_svm)\n",
    "print('Matriz de Confusión en Datos de Validación para SVM:')\n",
    "print(conf_matrix_val_svm)\n",
    "print('Matriz de Confusión en Datos de Prueba para SVM:')\n",
    "print(conf_matrix_test_svm)\n",
    "print(f'Error Cuadrático Medio en Datos de Entrenamiento para SVM: {mse_train_svm:.4f}')\n",
    "print(f'Error Cuadrático Medio en Datos de Validacion para SVM: {mse_val_svm:.4f}')\n",
    "print(f'Error Cuadrático Medio en Datos de Prueba para SVM: {mse_test_svm:.4f}')\n",
    "\n",
    "\n",
    "##RANDOM FOREST \n",
    "# Ahora para Random Forest\n",
    "# Dividir los datos para Random Forest de la misma manera que para MLP\n",
    "X_train_rf, X_temp_rf, y_train_rf, y_temp_rf = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "X_val_rf, X_test_rf, y_val_rf, y_test_rf = train_test_split(X_temp_rf, y_temp_rf, test_size=0.3, random_state=42)\n",
    "\n",
    "# Escalar los datos para Random Forest\n",
    "X_train_scaled_rf = scaler.fit_transform(X_train_rf)\n",
    "X_val_scaled_rf = scaler.transform(X_val_rf)\n",
    "X_test_scaled_rf = scaler.transform(X_test_rf)\n",
    "\n",
    "\n",
    "# Definir el modelo Random Forest\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Definir la cuadrícula de parámetros a explorar\n",
    "param_grid = {\n",
    "    'n_estimators': [50],\n",
    "    'max_depth':  [10],\n",
    "    'min_samples_split': [2],\n",
    "    'min_samples_leaf': [1],\n",
    "    'max_features':['sqrt']\n",
    "}\n",
    "# Configurar la búsqueda de cuadrícula\n",
    "grid_search_rf = GridSearchCV(estimator=rf_clf, param_grid=param_grid, cv=StratifiedKFold(n_splits=5), scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Realizar la búsqueda de cuadrícula en los datos de entrenamiento\n",
    "grid_search_rf.fit(X_train_scaled_rf, np.argmax(y_train_rf.to_numpy(), axis=1))\n",
    "\n",
    "\n",
    "\n",
    "# Evaluar el modelo con los mejores parámetros en datos de prueba\n",
    "best_rf_clf = grid_search_rf.best_estimator_\n",
    "accuracy_test_rf = accuracy_score(np.argmax(y_test_rf.to_numpy(), axis=1), best_rf_clf.predict(X_test_scaled_rf))\n",
    "\n",
    "# PASO 1: Datos de entrenamiento para Random Forest\n",
    "predictions_train_rf = best_rf_clf.predict(X_train_scaled_rf)\n",
    "accuracy_train_rf = accuracy_score(np.argmax(y_train_rf.to_numpy(), axis=1), predictions_train_rf)\n",
    "conf_matrix_train_rf = confusion_matrix(np.argmax(y_train_rf.to_numpy(), axis=1), predictions_train_rf)\n",
    "mse_train_rf = mean_squared_error(np.argmax(y_train_rf.to_numpy(), axis=1), predictions_train_rf)\n",
    "\n",
    "# PASO 2: Datos de validación para Random Forest\n",
    "predictions_val_rf = best_rf_clf.predict(X_val_scaled_rf)\n",
    "accuracy_val_rf = accuracy_score(np.argmax(y_val_rf.to_numpy(), axis=1), predictions_val_rf)\n",
    "conf_matrix_val_rf = confusion_matrix(np.argmax(y_val_rf.to_numpy(), axis=1), predictions_val_rf)\n",
    "mse_val_rf = mean_squared_error(np.argmax(y_val_rf.to_numpy(), axis=1), predictions_val_rf)\n",
    "\n",
    "# PASO 3: Datos de prueba para Random Forest\n",
    "predictions_test_rf = best_rf_clf.predict(X_test_scaled_rf)\n",
    "accuracy_test_rf = accuracy_score(np.argmax(y_test_rf.to_numpy(), axis=1), predictions_test_rf)\n",
    "conf_matrix_test_rf = confusion_matrix(np.argmax(y_test_rf.to_numpy(), axis=1), predictions_test_rf)\n",
    "mse_test_rf = mean_squared_error(np.argmax(y_test_rf.to_numpy(), axis=1), predictions_test_rf)\n",
    "\n",
    "print('\\n\\n')\n",
    "print('Resultados de Random Forest con Ajustes:')\n",
    "print(f'Precisión en entrenamiento: {accuracy_train_rf * 100:.2f}%')\n",
    "print(f'Precisión en prueba: {accuracy_test_rf * 100:.2f}%')\n",
    "print(f'Precisión en validación: {accuracy_val_rf * 100:.2f}%')\n",
    "print('\\n')\n",
    "print('Matriz de Confusión en Datos de Entrenamiento para Random Forest:')\n",
    "print(conf_matrix_train_rf)\n",
    "print('Matriz de Confusión en Datos de Validación para Random Forest:')\n",
    "print(conf_matrix_val_rf)\n",
    "print('Matriz de Confusión en Datos de Prueba para Random Forest:')\n",
    "print(conf_matrix_test_rf)\n",
    "print(f'Error Cuadrático Medio en Datos de Entrenamiento para Random Forest: {mse_train_rf:.4f}')\n",
    "print(f'Error Cuadrático Medio en Datos de Validacion para Random Forest: {mse_val_rf:.4f}')\n",
    "print(f'Error Cuadrático Medio en Datos de Prueba para Random Forest: {mse_test_rf:.4f}')\n",
    "\n",
    "\n",
    "\n",
    "# Dividir los datos para KNN de la misma manera que para MLP\n",
    "X_train_knn, X_temp_knn, y_train_knn, y_temp_knn = train_test_split(X, Y, test_size=0.15, random_state=42)\n",
    "X_val_knn, X_test_knn, y_val_knn, y_test_knn = train_test_split(X_temp_knn, y_temp_knn, test_size=0.6, random_state=42)\n",
    "\n",
    "# Escalar los datos para KNN\n",
    "scaler_knn = StandardScaler()\n",
    "X_train_scaled_knn = scaler_knn.fit_transform(X_train_knn)\n",
    "X_val_scaled_knn = scaler_knn.transform(X_val_knn)\n",
    "X_test_scaled_knn = scaler_knn.transform(X_test_knn)\n",
    "\n",
    "# Ajuste del número de vecinos (n_neighbors)\n",
    "param_grid = {'n_neighbors': [3, 5, 7, 9, 11]}\n",
    "knn_clf = KNeighborsClassifier()\n",
    "grid_search = GridSearchCV(knn_clf, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train_scaled_knn, np.argmax(y_train_knn.to_numpy(), axis=1))\n",
    "best_n_neighbors = grid_search.best_params_['n_neighbors']\n",
    "\n",
    "# Normalización de características\n",
    "X_train_scaled_knn = scaler_knn.fit_transform(X_train_knn)\n",
    "X_val_scaled_knn = scaler_knn.transform(X_val_knn)\n",
    "X_test_scaled_knn = scaler_knn.transform(X_test_knn)\n",
    "\n",
    "# KNN con pesos basados en la distancia\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=best_n_neighbors, weights='distance')\n",
    "knn_clf.fit(X_train_scaled_knn, np.argmax(y_train_knn.to_numpy(), axis=1))\n",
    "\n",
    "# Evaluación en datos de entrenamiento\n",
    "predictions_train_knn = knn_clf.predict(X_train_scaled_knn)\n",
    "accuracy_train_knn = accuracy_score(np.argmax(y_train_knn.to_numpy(), axis=1), predictions_train_knn)\n",
    "conf_matrix_train_knn = confusion_matrix(np.argmax(y_train_knn.to_numpy(), axis=1), predictions_train_knn)\n",
    "mse_train_knn = mean_squared_error(np.argmax(y_train_knn.to_numpy(), axis=1), predictions_train_knn)\n",
    "\n",
    "# Evaluación en datos de validación\n",
    "predictions_val_knn = knn_clf.predict(X_val_scaled_knn)\n",
    "accuracy_val_knn = accuracy_score(np.argmax(y_val_knn.to_numpy(), axis=1), predictions_val_knn)\n",
    "conf_matrix_val_knn = confusion_matrix(np.argmax(y_val_knn.to_numpy(), axis=1), predictions_val_knn)\n",
    "mse_val_knn = mean_squared_error(np.argmax(y_val_knn.to_numpy(), axis=1), predictions_val_knn)\n",
    "\n",
    "# Evaluación en datos de prueba\n",
    "predictions_test_knn = knn_clf.predict(X_test_scaled_knn)\n",
    "accuracy_test_knn = accuracy_score(np.argmax(y_test_knn.to_numpy(), axis=1), predictions_test_knn)\n",
    "conf_matrix_test_knn = confusion_matrix(np.argmax(y_test_knn.to_numpy(), axis=1), predictions_test_knn)\n",
    "mse_test_knn = mean_squared_error(np.argmax(y_test_knn.to_numpy(), axis=1), predictions_test_knn)\n",
    "\n",
    "# Llamada a la función de exportación para el modelo KNN\n",
    "export_knn_for_unity(knn_clf, scaler_knn, 'modelo_knn.joblib', 'escalador.joblib', 'formato_personalizado.txt')\n",
    "\n",
    "\n",
    "print('\\n\\n')\n",
    "print('Resultados de K-Nearest Neighbors (KNN):')\n",
    "print(f'Precisión en entrenamiento: {accuracy_train_knn * 100:.2f}%')\n",
    "print(f'Precisión en prueba: {accuracy_test_knn * 100:.2f}%')\n",
    "print(f'Precisión en validación: {accuracy_val_knn * 100:.2f}%')\n",
    "print('\\n')\n",
    "print('Matriz de Confusión en Datos de Entrenamiento para KNN:')\n",
    "print(conf_matrix_train_knn)\n",
    "print('Matriz de Confusión en Datos de Validación para KNN:')\n",
    "print(conf_matrix_val_knn)\n",
    "print('Matriz de Confusión en Datos de Prueba para KNN:')\n",
    "print(conf_matrix_test_knn)\n",
    "print(f'Error Cuadrático Medio en Datos de Entrenamiento para KNN: {mse_train_knn:.4f}')\n",
    "print(f'Error Cuadrático Medio en Datos de Validacion para KNN: {mse_val_knn:.4f}')\n",
    "print(f'Error Cuadrático Medio en Datos de Prueba para KNN: {mse_test_knn:.4f}')\n",
    "\n",
    "\n",
    "\n",
    "# Dividir los datos\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Escalar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Crear el modelo\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(Y.shape[1], activation='softmax'))  # Ajustar al número correcto de clases\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, validation_data=(X_val_scaled, y_val))\n",
    "\n",
    "# Evaluar en datos de prueba\n",
    "predictions = model.predict(X_test_scaled)\n",
    "rounded_predictions = np.argmax(predictions, axis=1)\n",
    "accuracy_dl = accuracy_score(np.argmax(y_test.to_numpy(), axis=1), rounded_predictions)\n",
    "conf_matrix_dl = confusion_matrix(np.argmax(y_test.to_numpy(), axis=1), rounded_predictions)\n",
    "mse_dl = mean_squared_error(np.argmax(y_test.to_numpy(), axis=1), rounded_predictions)\n",
    "\n",
    "# Imprimir resultados\n",
    "print(\"\\n\\nPrecisión en prueba (Deep Learning): {:.2%}\".format(accuracy_dl))\n",
    "print(\"Matriz de Confusión en Datos de Prueba (Deep Learning):\")\n",
    "print(conf_matrix_dl)\n",
    "print(\"Error Cuadrático Medio en Datos de Prueba (Deep Learning): {:.4f}\".format(mse_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a96ef17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Resumen del Análisis ###\n",
      "1. Red Neuronal Personalizada:\n",
      "   - Desventajas:\n",
      "     - Requiere ajuste manual de hiperparámetros.\n",
      "     - La precisión en entrenamiento es relativamente baja.\n",
      "     - La precisión en prueba y validación cruzada es más baja que la de Random Forest.\n",
      "   - Razones:\n",
      "     - La red neuronal podría no haber tenido suficiente complejidad.\n",
      "     - Posiblemente sufrió de sobreajuste o subajuste.\n",
      "2. MLPClassifier de SKLearn (sin modificar):\n",
      "   - Desventajas:\n",
      "     - Precisión en entrenamiento y prueba relativamente bajas.\n",
      "     - Requiere ajuste de hiperparámetros para mejorar el rendimiento.\n",
      "     - No se explora la variación de hiperparámetros en detalle.\n",
      "   - Razones:\n",
      "     - La configuración inicial de hiperparámetros puede no haber sido óptima.\n",
      "     - No se realiza una búsqueda exhaustiva de hiperparámetros \n",
      "3. MLPClassifier de SKLearn (modificado):\n",
      "   - Desventajas:\n",
      "     - Precisión en entrenamiento y prueba relativamente bajas antes de ajustes.\n",
      "     - Requiere escalado de datos.\n",
      "     - No se explora la variación de hiperparámetros en detalle.\n",
      "   - Razones:\n",
      "     - La configuración inicial de hiperparámetros puede no haber sido óptima.\n",
      "4. SVM con Ajustes:\n",
      "   - Desventajas:\n",
      "     - Precisión en prueba relativamente baja.\n",
      "     - Requiere escalado de datos, lo que puede ser una molestia.\n",
      "   - Razones:\n",
      "     - SVM puede no haber sido capaz de capturar patrones no lineales sin un kernel no lineal.\n",
      "     - La elección del kernel no se explora en detalle.\n",
      "5. Random Forest con Ajustes:\n",
      "   - Ventajas:\n",
      "     - Mayor precisión en prueba y validación cruzada.\n",
      "     - Capacidad para manejar características irrelevantes y ruido.\n",
      "     - Menos propenso al sobreajuste y no requiere escalado de datos.\n",
      "   - Razones:\n",
      "     - Random Forest es robusto y versátil, y tiende a funcionar bien incluso sin ajustes finos.\n",
      "     - Puede manejar múltiples características y relaciones no lineales sin requerir preprocesamiento intensivo de datos.\n",
      "6. K-Nearest Neighbors (KNN) con Ajustes:\n",
      "Ventajas:\n",
      "- Simplicidad conceptual: KNN es fácil de entender e implementar.\n",
      "- No asume distribuciones específicas de datos y puede funcionar bien en conjuntos de datos no lineales.\n",
      "- Capacidad para adaptarse a cambios en la distribución de datos a lo largo del tiempo (aprendizaje no paramétrico).\n",
      "Desventajas:\n",
      "- Sensible a la elección del número de vecinos (n_neighbors), lo cual puede requerir ajustes manuales.\n",
      "- Requiere escalado de datos para asegurar que todas las características contribuyan de manera equitativa.\n",
      "- Puede ser computacionalmente costoso en conjuntos de datos grandes.\n",
      "Razones:\n",
      "- La elección del número de vecinos puede afectar significativamente el rendimiento de KNN. Un valor incorrecto podría llevar a sobreajuste o subajuste.\n",
      "- La necesidad de escalar datos es una limitación inherente de KNN, ya que la medida de distancia euclidiana es sensible a la escala de las características.\n",
      "- La eficacia de KNN depende de la estructura del espacio de características; podría no funcionar bien si las clases no están bien separadas.\n",
      "Resumen General y Elección del Modelo:\n",
      "Comparando todos los modelos:\n",
      "- La red neuronal personalizada tuvo un rendimiento inferior, posiblemente debido a la complejidad del modelo o la necesidad de ajustes más finos.\n",
      "- MLPClassifier de SKLearn y SVM mostraron cierta mejora después de ajustes, pero la precisión sigue siendo relativamente baja.\n",
      "- Random Forest se destacó con una mayor precisión en prueba y validación cruzada, siendo más robusto y menos propenso al sobreajuste.\n",
      "- KNN podría ser una opción adicional, pero su rendimiento dependerá críticamente de la elección correcta de hiperparámetros y la naturaleza del conjunto de datos.\n",
      "7. Modelo de Deep Learning (CNN):\n",
      "   Ventajas:\n",
      "   - Captura patrones complejos mediante capas convolucionales.\n",
      "   - Adecuado para identificar relaciones no lineales en datos.\n",
      "   - Aprendizaje de características automáticamente durante el entrenamiento.\n",
      "   - Potencial para mayor rendimiento con ajuste de hiperparámetros y arquitectura.\n",
      "   Desventajas:\n",
      "   - Requiere más tiempo y recursos computacionales para entrenar.\n",
      "   - Mayor complejidad y dificultad en la interpretación del modelo.\n",
      "   - Sensible a sobreajuste, especialmente en conjuntos de datos pequeños.\n",
      "   Razones:\n",
      "   - La arquitectura convolucional es adecuada para datos con patrones espaciales, como imágenes.\n",
      "   - La capacidad para aprender características jerárquicas puede beneficiar en problemas complejos.\n",
      "   - Aunque Random Forest ha mostrado buen rendimiento, el modelo de Deep Learning podría mejorar con ajustes finos y más datos.\n",
      "Elección Final:   Random Forest\n",
      "\n",
      "Manejo de Relaciones no Lineales:\n",
      "\n",
      "Para nuestro juego de coches podemos tener relaciones no lineales entre las características (atributos) y las clases (acciones del jugador). Random Forest es conocido por su capacidad inherente para modelar relaciones no lineales de manera efectiva. Cada árbol en el bosque puede capturar patrones complejos, y la combinación de múltiples árboles mejora la capacidad del modelo para adaptarse a la complejidad del problema.\n",
      "\n",
      "Robustez y Generalización:\n",
      "Random Forest es menos propenso al sobreajuste en comparación con KNN. Aunque KNN ha demostrado una precisión del 100% en el conjunto de entrenamiento, esto puede indicar sobreajuste, ya que el modelo puede haber memorizado los datos en lugar de aprender patrones subyacentes. Random Forest tiende a generalizar mejor a nuevos datos, como se refleja en la precisión en los conjuntos de prueba y validación.\n",
      "\n",
      "Manejo Eficiente de Características Irrelevantes:\n",
      "Random Forest es robusto frente a características irrelevantes. Puede manejar conjuntos de datos con características que no contribuyen significativamente a la predicción sin requerir un preprocesamiento intensivo. En problemas del mundo real, puede haber muchas características, y RF puede lidiar con ellas de manera más efectiva.\n",
      "\n",
      "Menor Sensibilidad a la Elección de Hiperparámetros:\n",
      "Random Forest suele ser menos sensible a la elección precisa de hiperparámetros en comparación con KNN. Esto hace que sea más fácil de usar y ajustar.\n",
      "\n",
      "Capacidad para Manejar Conjuntos de Datos Desbalanceados:\n",
      "Si hay desequilibrios en la distribución de las clases (por ejemplo, si hay más ejemplos de una clase que de otra), Random Forest puede manejar esto de manera más efectiva que KNN.\n",
      "\n",
      "Eficiencia Computacional:\n",
      "Random Forest puede manejar conjuntos de datos grandes de manera más eficiente que KNN. KNN, al ser basado en instancias, puede volverse computacionalmente costoso a medida que el tamaño del conjunto de datos aumenta.\n",
      "Deep learning nos ofrece unos buenos resultados pero sirve bien con grandes cantidades de datos y si la relación es compleja, en nuestro caso no estamos haciendo uso\n",
      "de una gran cantidad de datos,\n",
      "      \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"\\n ### Resumen del Análisis ###\")\n",
    "\n",
    "# 1. Red Neuronal Personalizada:\n",
    "print(\"1. Red Neuronal Personalizada:\")\n",
    "print(\"   - Desventajas:\")\n",
    "print(\"     - Requiere ajuste manual de hiperparámetros.\")\n",
    "print(\"     - La precisión en entrenamiento es relativamente baja.\")\n",
    "print(\"     - La precisión en prueba y validación cruzada es más baja que la de Random Forest.\")\n",
    "print(\"   - Razones:\")\n",
    "print(\"     - La red neuronal podría no haber tenido suficiente complejidad.\")\n",
    "print(\"     - Posiblemente sufrió de sobreajuste o subajuste.\")\n",
    "\n",
    "# 2. MLPClassifier de SKLearn (sin modificar):\n",
    "print(\"2. MLPClassifier de SKLearn (sin modificar):\")\n",
    "print(\"   - Desventajas:\")\n",
    "print(\"     - Precisión en entrenamiento y prueba relativamente bajas.\")\n",
    "print(\"     - Requiere ajuste de hiperparámetros para mejorar el rendimiento.\")\n",
    "print(\"     - No se explora la variación de hiperparámetros en detalle.\")\n",
    "print(\"   - Razones:\")\n",
    "print(\"     - La configuración inicial de hiperparámetros puede no haber sido óptima.\")\n",
    "print(\"     - No se realiza una búsqueda exhaustiva de hiperparámetros \")\n",
    "\n",
    "# 3. MLPClassifier de SKLearn (modificado):\n",
    "print(\"3. MLPClassifier de SKLearn (modificado):\")\n",
    "print(\"   - Desventajas:\")\n",
    "print(\"     - Precisión en entrenamiento y prueba relativamente bajas antes de ajustes.\")\n",
    "print(\"     - Requiere escalado de datos.\")\n",
    "print(\"     - No se explora la variación de hiperparámetros en detalle.\")\n",
    "print(\"   - Razones:\")\n",
    "print(\"     - La configuración inicial de hiperparámetros puede no haber sido óptima.\")\n",
    "\n",
    "# 4. SVM con Ajustes:\n",
    "print(\"4. SVM con Ajustes:\")\n",
    "print(\"   - Desventajas:\")\n",
    "print(\"     - Precisión en prueba relativamente baja.\")\n",
    "print(\"     - Requiere escalado de datos, lo que puede ser una molestia.\")\n",
    "print(\"   - Razones:\")\n",
    "print(\"     - SVM puede no haber sido capaz de capturar patrones no lineales sin un kernel no lineal.\")\n",
    "print(\"     - La elección del kernel no se explora en detalle.\")\n",
    "\n",
    "# 5. Random Forest con Ajustes:\n",
    "print(\"5. Random Forest con Ajustes:\")\n",
    "print(\"   - Ventajas:\")\n",
    "print(\"     - Mayor precisión en prueba y validación cruzada.\")\n",
    "print(\"     - Capacidad para manejar características irrelevantes y ruido.\")\n",
    "print(\"     - Menos propenso al sobreajuste y no requiere escalado de datos.\")\n",
    "print(\"   - Razones:\")\n",
    "print(\"     - Random Forest es robusto y versátil, y tiende a funcionar bien incluso sin ajustes finos.\")\n",
    "print(\"     - Puede manejar múltiples características y relaciones no lineales sin requerir preprocesamiento intensivo de datos.\")\n",
    "\n",
    "# 5.KNN:\n",
    "print(\"6. K-Nearest Neighbors (KNN) con Ajustes:\")\n",
    "print(\"Ventajas:\")\n",
    "print(\"- Simplicidad conceptual: KNN es fácil de entender e implementar.\")\n",
    "print(\"- No asume distribuciones específicas de datos y puede funcionar bien en conjuntos de datos no lineales.\")\n",
    "print(\"- Capacidad para adaptarse a cambios en la distribución de datos a lo largo del tiempo (aprendizaje no paramétrico).\")\n",
    "print(\"Desventajas:\")\n",
    "print(\"- Sensible a la elección del número de vecinos (n_neighbors), lo cual puede requerir ajustes manuales.\")\n",
    "print(\"- Requiere escalado de datos para asegurar que todas las características contribuyan de manera equitativa.\")\n",
    "print(\"- Puede ser computacionalmente costoso en conjuntos de datos grandes.\")\n",
    "print(\"Razones:\")\n",
    "print(\"- La elección del número de vecinos puede afectar significativamente el rendimiento de KNN. Un valor incorrecto podría llevar a sobreajuste o subajuste.\")\n",
    "print(\"- La necesidad de escalar datos es una limitación inherente de KNN, ya que la medida de distancia euclidiana es sensible a la escala de las características.\")\n",
    "print(\"- La eficacia de KNN depende de la estructura del espacio de características; podría no funcionar bien si las clases no están bien separadas.\")\n",
    "print(\"Resumen General y Elección del Modelo:\")\n",
    "print(\"Comparando todos los modelos:\")\n",
    "print(\"- La red neuronal personalizada tuvo un rendimiento inferior, posiblemente debido a la complejidad del modelo o la necesidad de ajustes más finos.\")\n",
    "print(\"- MLPClassifier de SKLearn y SVM mostraron cierta mejora después de ajustes, pero la precisión sigue siendo relativamente baja.\")\n",
    "print(\"- Random Forest se destacó con una mayor precisión en prueba y validación cruzada, siendo más robusto y menos propenso al sobreajuste.\")\n",
    "print(\"- KNN podría ser una opción adicional, pero su rendimiento dependerá críticamente de la elección correcta de hiperparámetros y la naturaleza del conjunto de datos.\")\n",
    "# Modelo de Deep Learning (CNN):\n",
    "print(\"7. Modelo de Deep Learning (CNN):\")\n",
    "print(\"   Ventajas:\")\n",
    "print(\"   - Captura patrones complejos mediante capas convolucionales.\")\n",
    "print(\"   - Adecuado para identificar relaciones no lineales en datos.\")\n",
    "print(\"   - Aprendizaje de características automáticamente durante el entrenamiento.\")\n",
    "print(\"   - Potencial para mayor rendimiento con ajuste de hiperparámetros y arquitectura.\")\n",
    "print(\"   Desventajas:\")\n",
    "print(\"   - Requiere más tiempo y recursos computacionales para entrenar.\")\n",
    "print(\"   - Mayor complejidad y dificultad en la interpretación del modelo.\")\n",
    "print(\"   - Sensible a sobreajuste, especialmente en conjuntos de datos pequeños.\")\n",
    "print(\"   Razones:\")\n",
    "print(\"   - La arquitectura convolucional es adecuada para datos con patrones espaciales, como imágenes.\")\n",
    "print(\"   - La capacidad para aprender características jerárquicas puede beneficiar en problemas complejos.\")\n",
    "print(\"   - Aunque Random Forest ha mostrado buen rendimiento, el modelo de Deep Learning podría mejorar con ajustes finos y más datos.\")\n",
    "\n",
    "print(\"Elección Final:   Random Forest\")\n",
    "print(\"\"\"\n",
    "Manejo de Relaciones no Lineales:\n",
    "\n",
    "Para nuestro juego de coches podemos tener relaciones no lineales entre las características (atributos) y las clases (acciones del jugador). Random Forest es conocido por su capacidad inherente para modelar relaciones no lineales de manera efectiva. Cada árbol en el bosque puede capturar patrones complejos, y la combinación de múltiples árboles mejora la capacidad del modelo para adaptarse a la complejidad del problema.\n",
    "\n",
    "Robustez y Generalización:\n",
    "Random Forest es menos propenso al sobreajuste en comparación con KNN. Aunque KNN ha demostrado una precisión del 100% en el conjunto de entrenamiento, esto puede indicar sobreajuste, ya que el modelo puede haber memorizado los datos en lugar de aprender patrones subyacentes. Random Forest tiende a generalizar mejor a nuevos datos, como se refleja en la precisión en los conjuntos de prueba y validación.\n",
    "\n",
    "Manejo Eficiente de Características Irrelevantes:\n",
    "Random Forest es robusto frente a características irrelevantes. Puede manejar conjuntos de datos con características que no contribuyen significativamente a la predicción sin requerir un preprocesamiento intensivo. En problemas del mundo real, puede haber muchas características, y RF puede lidiar con ellas de manera más efectiva.\n",
    "\n",
    "Menor Sensibilidad a la Elección de Hiperparámetros:\n",
    "Random Forest suele ser menos sensible a la elección precisa de hiperparámetros en comparación con KNN. Esto hace que sea más fácil de usar y ajustar.\n",
    "\n",
    "Capacidad para Manejar Conjuntos de Datos Desbalanceados:\n",
    "Si hay desequilibrios en la distribución de las clases (por ejemplo, si hay más ejemplos de una clase que de otra), Random Forest puede manejar esto de manera más efectiva que KNN.\n",
    "\n",
    "Eficiencia Computacional:\n",
    "Random Forest puede manejar conjuntos de datos grandes de manera más eficiente que KNN. KNN, al ser basado en instancias, puede volverse computacionalmente costoso a medida que el tamaño del conjunto de datos aumenta.\n",
    "Deep learning nos ofrece unos buenos resultados pero sirve bien con grandes cantidades de datos y si la relación es compleja, en nuestro caso no estamos haciendo uso\n",
    "de una gran cantidad de datos,\n",
    "      \n",
    "    \"\"\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1e7616",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44f2f750",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9d6bdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ea6a63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3539cb71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731dff0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
