{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hoja de Ejercicios y Problemas tipo examen 2\n",
    "Ismael Sagredo Olivenza\n",
    "Colaboraci√≥n en este material de Bel√©n D√≠az Agudo y otros profesores de ISIA\n",
    "## Problema 01\n",
    "Tenemos un dataset con datos almacenados sobre las precipitaciones desde hace 10\n",
    "a√±os y queremos predecir el nivel de precipitaci√≥n en el futuro en funci√≥n del dia del\n",
    "a√±o (entero), la humedad (real), la cantidad de nubosidad (baja, media, alta), la\n",
    "temperatura (real) y la presi√≥n atmosf√©rica (real).\n",
    "Hemos aplicado diferentes t√©cnicas de Machine Learning y nos ha generado los\n",
    "siguientes resultados de accuracy:\n",
    "\n",
    "- KNN: K=5, 88% distancia eucl√≠dea.\n",
    "- Decision Tree: 90%, profundidad del √°rbol 5.\n",
    "- Random Forest: 98%\n",
    "- Perceptr√≥n Multicapa: 10 neuronas ocultas en la primera capa y 5 en la segunda,\n",
    "factor de aprendiszaje de 0,2, valores normalizados 0-1: 90%\n",
    "\n",
    "A los investigadores les ha sorprendido que el perceptr√≥n multicapa de resultados tan\n",
    "bajos.\n",
    "\n",
    "1. ¬øQu√© podriamos hacer para mejorar los resultados del perceptr√≥n?\n",
    "2. Con los datos del ejercicio, razona cual ser√≠a el modelo que elegir√≠as.\n",
    "3. En KNN el valor categ√≥rico ha sido codificado como 0, 1, 2 y el resto de atributos\n",
    "para calcular la diferencia se realizan restando sus valores sin ninguna\n",
    "transformaci√≥n. ¬øC√≥mo podr√≠amos mejorar KNN para conseguir mejores\n",
    "resultados?\n",
    "\n",
    "### Respuesta ChatGPT\n",
    "1. Para mejorar los resultados del perceptr√≥n multicapa, podr√≠amos considerar las siguientes estrategias:\n",
    "   - Ajustar la arquitectura de la red: Experimentar con diferentes configuraciones de capas y unidades ocultas puede influir significativamente en el rendimiento del perceptr√≥n.\n",
    "   - Tuning de hiperpar√°metros: Ajustar el factor de aprendizaje, el n√∫mero de √©pocas y otros hiperpar√°metros del modelo puede mejorar la convergencia y el rendimiento general.\n",
    "   - Normalizaci√≥n de datos: Asegurarse de que los datos est√©n correctamente normalizados puede ser crucial para el rendimiento del perceptr√≥n multicapa. Aseg√∫rate de que todas las caracter√≠sticas est√©n en una escala similar (por ejemplo, entre 0 y 1).\n",
    "   - Regularizaci√≥n: Introducir t√©cnicas de regularizaci√≥n como la penalizaci√≥n L1 o L2 puede ayudar a prevenir el sobreajuste y mejorar la generalizaci√≥n del modelo.\n",
    "\n",
    "2. Bas√°ndonos en los resultados proporcionados:\n",
    "   - El modelo Random Forest muestra el mayor rendimiento con un 98% de precisi√≥n, lo que sugiere una buena capacidad de generalizaci√≥n y robustez.\n",
    "   - El Decision Tree tambi√©n tiene un rendimiento s√≥lido con un 90% de precisi√≥n.\n",
    "   - KNN tiene un rendimiento aceptable, pero puede beneficiarse de ajustes en la elecci√≥n de K y la m√©trica de distancia.\n",
    "   - El Perceptr√≥n Multicapa, a pesar de su rendimiento m√°s bajo del 90%, podr√≠a mejorarse mediante la exploraci√≥n de las estrategias mencionadas anteriormente.\n",
    "\n",
    "3. Para mejorar KNN y obtener mejores resultados, podr√≠amos considerar:\n",
    "   - Optimizaci√≥n de K: Experimentar con diferentes valores de K para encontrar el √≥ptimo para el conjunto de datos particular.\n",
    "   - Selecci√≥n de m√©trica de distancia: Probar otras m√©tricas de distancia adem√°s de la distancia euclidiana, como la distancia de Mahalanobis o la distancia de Minkowski.\n",
    "   - Normalizaci√≥n de atributos: Normalizar los atributos puede ser crucial en KNN, ya que las diferencias en la escala de los atributos pueden afectar significativamente a las distancias calculadas.\n",
    "   - Evaluaci√≥n de ponderaci√≥n: Algunas implementaciones de KNN permiten ponderar las contribuciones de los vecinos en funci√≥n de su distancia; experimentar con esto puede mejorar el rendimiento.\n",
    "\n",
    "### Respuesta Isma\n",
    "1. ¬øQu√© podriamos hacer para mejorar los resultados del perceptr√≥n?\n",
    "\n",
    "El factor de aprendizaje quiz√°s est√© muy alto, podr√≠amos reentrenar la red con otro\n",
    "factor de aprendizaje. Tambien podr√≠amos modificar la arquitectura de la red o\n",
    "seleccionar los atributos\n",
    "\n",
    "2. Con los datos del ejercicio, razona cual ser√≠a el modelo que elegir√≠as.\n",
    "\n",
    "La respuesta peude ser variada y si est√° argumentada ser√≠a correcta. Por un lado\n",
    "podemos pensar que un 90% es suficiente y elegir arboles de decisi√≥n por ser un\n",
    "algoritmo de caja blanca. Tenemos que tener en cuenta que saber si va a llover o no es\n",
    "algo que tiene importancia para hoteles o para saber si te vas de vacaciones o no, pero\n",
    "si 9 de cada 10 veces se va a acertar, no es un mal rendimiento. Si lo que queremos es\n",
    "maximizar la precisi√≥n usar√≠amos random forest, pero tenemos que ser conscientes\n",
    "que perdemos explicabilidad.\n",
    "\n",
    "3. En KNN el valor categ√≥rico ha sido codificado como 0, 1, 2 y el resto de atributos\n",
    "para calcular la diferencia se realizan restando sus valores sin ninguna\n",
    "transformaci√≥n. ¬øC√≥mo podr√≠amos mejorar KNN para conseguir mejores\n",
    "resultados?\n",
    "\n",
    "Podriamos aplicar one-hot-enconding para codificar los valores categ√≥ricos. Tambien\n",
    "estaria bien normalizar el resto de valores. Bien aplicando una resta de la normal y\n",
    "dividiendo por la desviaci√≥n t√≠pica o bien haciendo que todos los datos esten entre 0 y 1.\n",
    "Esto har√≠a que la distancia eucl√≠dea represente mejor al individuo.\n",
    "\n",
    "### Claves de la respuesta\n",
    "1. Jugar con la arquitectura del modelo, el factor de aprendizaje, asegurar normalizaci√≥n correcta, y usar regularizaci√≥n L2 para evitar sobreajustes.\n",
    "2. Si nos interesa s√≥lo la precisi√≥n, usar Random Forest. Si queremos ver el proceso de decisi√≥n, usar Decision Tree.\n",
    "3. Usar one-hot-encoding y normalizaci√≥n.\n",
    "\n",
    "## Problema 2\n",
    "En un problema de Machine Learning, hemos utilizado la librer√≠a train_test_split para\n",
    "dividir el conjunto de entrenamiento y de test. En concreto se ha utilizado con los\n",
    "siguientes valores train_test_split(data, y, train_size = 0.8, random_state = 1)\n",
    "Sin embargo, haciendo pruebas vemos que en funci√≥n del random_state o del tama√±o\n",
    "de los datos de entrenamiento el resultado varia hasta un 5% de precisi√≥n.\n",
    "1. ¬øC√≥mo podr√≠amos abordar este problema?\n",
    "\n",
    "### Respuesta ChatGPT\n",
    "La variabilidad en los resultados del modelo de Machine Learning debido a la aleatoriedad en la divisi√≥n de los conjuntos de entrenamiento y prueba puede abordarse de varias maneras:\n",
    "\n",
    "1. **Fijar la Semilla (Random State):** Si deseas obtener resultados reproducibles, puedes fijar la semilla (random_state) a un valor espec√≠fico. Esto garantiza que, cada vez que ejecutas el c√≥digo, obtendr√°s la misma divisi√≥n de conjuntos de entrenamiento y prueba. Por ejemplo, `random_state = 1`.\n",
    "\n",
    "   ```python\n",
    "   train_test_split(data, y, train_size=0.8, random_state=1)\n",
    "   ```\n",
    "\n",
    "   Aseg√∫rate de documentar y compartir la semilla utilizada para que otros puedan reproducir los resultados.\n",
    "\n",
    "2. **Validaci√≥n Cruzada (Cross-Validation):** En lugar de depender de una sola divisi√≥n de entrenamiento/prueba, puedes utilizar t√©cnicas de validaci√≥n cruzada. K-Fold Cross-Validation implica dividir los datos en k particiones, entrenar y evaluar el modelo k veces, utilizando diferentes particiones como conjunto de prueba en cada iteraci√≥n. Esto proporciona una evaluaci√≥n m√°s robusta del rendimiento del modelo.\n",
    "\n",
    "   ```python\n",
    "   from sklearn.model_selection import cross_val_score\n",
    "\n",
    "   scores = cross_val_score(model, data, y, cv=5)  # Ejemplo con k=5\n",
    "   ```\n",
    "\n",
    "3. **Ajuste del Tama√±o del Conjunto de Entrenamiento:** El tama√±o del conjunto de entrenamiento tambi√©n puede influir en los resultados. Puedes experimentar con diferentes tama√±os de conjunto de entrenamiento y evaluar c√≥mo afecta al rendimiento. Aseg√∫rate de tener suficientes datos en el conjunto de prueba para obtener una evaluaci√≥n significativa del rendimiento del modelo.\n",
    "\n",
    "   ```python\n",
    "   train_test_split(data, y, train_size=0.7, random_state=1)  # Ejemplo con un 70% de entrenamiento\n",
    "   ```\n",
    "\n",
    "4. **An√°lisis Detallado:** Realizar un an√°lisis detallado de por qu√© los resultados var√≠an. Puede haber patrones particulares en los datos que se manifiesten solo en ciertas divisiones. Aseg√∫rate de explorar las caracter√≠sticas de los datos y entender si hay alg√∫n sesgo o patr√≥n que pueda explicar las diferencias en la precisi√≥n.\n",
    "\n",
    "Al implementar estas estrategias, puedes reducir la variabilidad en los resultados y obtener una evaluaci√≥n m√°s robusta del rendimiento del modelo.\n",
    "\n",
    "### Respuesta Isma\n",
    "La mejor forma de abordar este problema es usando cross validation. Con esta t√©cnica\n",
    "calculamos el error medio entre diferentes particiones del dataset entre datos de\n",
    "entrenamiento y de validaci√≥n, lo que minimiza la desviaci√≥n que puede producir una\n",
    "mala partici√≥n del dataset entre entrenamiento y validaci√≥n.\n",
    "\n",
    "### Claves de la respuesta\n",
    "Quiere que le expliques Cross-validation, ya que sirve precisamente para estos casos.\n",
    "\n",
    "## Pregunta 3\n",
    "Queremos detectar a partir de im√°genes de rayos X si existe o no un tumor cerebral.\n",
    "Para ello disponemos de un dataset con 100.000 im√°genes de 1024x1024 en escala de\n",
    "grises.\n",
    "\n",
    "1. Explica los pasos que har√≠as para preparar los datos\n",
    "2. A priori, cual crees que ser√≠a el mejor modelo y porqu√©.\n",
    "3. Suponiendo que se han creado dos modelos y con 2000 datos de validaci√≥n, el\n",
    "modelo A y el modelo B, ¬øqu√© modelo elegir√≠as?\n",
    "\n",
    "La matriz de confusi√≥n de A es:\n",
    "\n",
    "|          | Tumor | No-tumor |\n",
    "|----------|-------|----------|\n",
    "| **Tumor**   | 800   | 200      |\n",
    "| **No-tumor**| 100   | 900      |\n",
    "\n",
    "La matriz de confusi√≥n de B es:\n",
    "\n",
    "|          | Tumor | No-tumor |\n",
    "|----------|-------|----------|\n",
    "| **Tumor**   | 900   | 100      |\n",
    "| **No-tumor**| 200   | 800      |\n",
    "\n",
    "### Respuesta ChatGpt\n",
    "1. **Pasos para preparar los datos:**\n",
    "   - **Exploraci√≥n de datos:** Analizar algunas im√°genes para entender su formato y caracter√≠sticas. Verificar si hay desequilibrios en las clases.\n",
    "   - **Preprocesamiento:** Redimensionar las im√°genes a un tama√±o manejable, normalizar los valores de p√≠xeles (escala de 0 a 1), y realizar cualquier ajuste necesario para mejorar la calidad de las im√°genes.\n",
    "   - **Etiquetado:** Asignar etiquetas a las im√°genes seg√∫n la presencia o ausencia de un tumor cerebral.\n",
    "   - **Divisi√≥n del conjunto de datos:** Separar los datos en conjuntos de entrenamiento, validaci√≥n y prueba.\n",
    "   - **Data Augmentation (si es necesario):** Generar versiones adicionales de las im√°genes mediante rotaci√≥n, inversi√≥n, zoom, etc., para aumentar la variabilidad del conjunto de entrenamiento.\n",
    "   \n",
    "2. **Elecci√≥n del mejor modelo:**\n",
    "   - Dada la naturaleza de las im√°genes m√©dicas, las redes neuronales convolucionales (CNN) son com√∫nmente utilizadas para tareas de clasificaci√≥n de im√°genes. Por lo tanto, un modelo de CNN ser√≠a una elecci√≥n natural para este problema. Adem√°s, las CNN son eficientes para aprender patrones espaciales en im√°genes.\n",
    "\n",
    "3. **Comparaci√≥n de modelos A y B:**\n",
    "   - **Modelo A:**\n",
    "     - Verdaderos positivos (TP): 800\n",
    "     - Verdaderos negativos (TN): 900\n",
    "     - Falsos positivos (FP): 200\n",
    "     - Falsos negativos (FN): 100\n",
    "     - Precisi√≥n = (TP + TN) / (TP + TN + FP + FN) = (800 + 900) / (800 + 900 + 200 + 100) ‚âà 0.86\n",
    "   - **Modelo B:**\n",
    "     - Verdaderos positivos (TP): 900\n",
    "     - Verdaderos negativos (TN): 800\n",
    "     - Falsos positivos (FP): 100\n",
    "     - Falsos negativos (FN): 200\n",
    "     - Precisi√≥n = (TP + TN) / (TP + TN + FP + FN) = (900 + 800) / (900 + 800 + 100 + 200) ‚âà 0.85\n",
    "\n",
    "   Ambos modelos tienen una precisi√≥n similar, pero la elecci√≥n entre ellos podr√≠a depender de otros factores como la sensibilidad (recall), la especificidad, el F1-score, etc. Tambi√©n, podr√≠as considerar la interpretaci√≥n cl√≠nica y los requisitos espec√≠ficos del problema.\n",
    "\n",
    "### Respuesta Isma\n",
    "1. Explica los pasos que har√≠as para preparar los datos\n",
    "\n",
    "Las im√°genes son demasiado grandes habr√≠a que escalarlas a un tama√±o m√°s\n",
    "manejable, como por ejemplo 64x64. Podemos escalarlas a mano usando alguna\n",
    "algoritmos de escaldo, o podriamos intantar extraer las caracteristicas de una imagen\n",
    "como etapa de preprocesado inicial. Para ello podemos utilizar un Autoencoder o un\n",
    "algortimo de PCA. Por otro lado usando PCA dibujar√≠a las diferentes clases para ver\n",
    "que pinta tiene. Tambien se podr√≠a hacer un an√°lisis de las im√°genes y detectar que\n",
    "pixeles aportan m√°s informaci√≥n y hasta que punto podemos recortar las im√°genes.\n",
    "\n",
    "2. A priori, cual crees que ser√≠a el mejor modelo y porqu√©.\n",
    "\n",
    "A priori el mejor modelo para procesar im√°genes de los que hemos estudiado son las\n",
    "redes de neuronas convolucionales y los autoencoders. Tambien a priori el perceptr√≥n\n",
    "multicapa se comporta mejor en este tipo de problemas que otros algoritmos. Pero no\n",
    "podemos asegurarlo a ciencia cierta hasta hacer pruebas.\n",
    "\n",
    "3. Suponiendo que se han creado dos modelos y con 2000 datos de validaci√≥n, el\n",
    "modelo A y el modelo B, ¬øqu√© modelo elegir√≠as?\n",
    "\n",
    "El modelo B ya que es m√°s importante que no haya falsos positivos, es decir que\n",
    "habiendo un tumor se clasifique como no tumor. Es peor este resultado que clasificar\n",
    "como tumor algo que no lo tiene, ya que normalmente se le realizaran otras pruebas\n",
    "antes de darle un diagnostico final.\n",
    "\n",
    "### Claves de la respuesta\n",
    "1. Las imagenes deben reducirse en tama√±o y complejidad, ya sea reescal√°ndolas de\n",
    "forma manual o usando convoluci√≥n, autoencoders o PCA.\n",
    "2. Las redes neuronales convolucionales se especializan en im√°genes.\n",
    "3. Este problema es serio y es muy importante detectar los positivos. \n",
    "Fallar en los negativos nos importa menos.\n",
    "\n",
    "## Problema 4\n",
    "Hemos conectado al videojuego Tetris un m√≥dulo que captura los eventos del mando,\n",
    "que se van registrando a la vez que se va haciendo una foto del estado del jugador. La\n",
    "idea es construir un sistema que permite jugar de forma aut√≥noma a un agente que\n",
    "debe jugar igual que el jugador para el modo versus, donde un jugador juega contra\n",
    "una IA. Para ellos almacenamos en un hist√≥rico el estado del juego y la acci√≥n que ha\n",
    "realizado el jugador que puede ser una de las siguientes:\n",
    "\n",
    "- Mover Izquierda (MI)\n",
    "- Mover derecha (MD)\n",
    "- Rotar pieza (R)\n",
    "- Bajar pieza (B)\n",
    "- Guardar pieza (G)\n",
    "\n",
    "El estado est√° compuesto por una matriz con las celdas ocupadas por piezas, el nivel\n",
    "actual, la posici√≥n de la pieza que cae actualmente, la siguiente pieza y la pieza\n",
    "almacenada de repuesto.\n",
    "\n",
    "Si queremos utilizar KNN para seleccionar la acci√≥n m√°s similar a la realizada por el\n",
    "usuario‚Ä¶.\n",
    "\n",
    "1. ¬øComo codificar√≠as los datos para que KNN pueda funcionar correctamente y que\n",
    "medida de distancia usar√≠as?\n",
    "2. Para saber si el agente imita correctamente al jugador, comprobamos que la\n",
    "secuencia de acciones realizadas por el agente sea similar a la del jugador para un\n",
    "estado de juego dado (El Tetris es determinista asumiendo la misma semilla\n",
    "aleatoria) De esta forma tendremos la secuencia de acciones MI|MD|R|B|MI|MI|B|G|MD|MI|MD|R|R|B.\n",
    "¬øQu√© medida de distancia utilizar√≠as para calcular el error?\n",
    "\n",
    "### Respuesta ChatGPT\n",
    "1. **Codificaci√≥n de Datos para KNN:**\n",
    "   - Cada estado del juego y acci√≥n realizada por el jugador debe ser codificado en un formato num√©rico para que KNN pueda operar. Puedes utilizar un enfoque de \"one-hot encoding\" para las acciones y convertir el estado del juego en un vector unidimensional, incluyendo todos los elementos relevantes (matriz de celdas ocupadas, nivel, posici√≥n de la pieza actual, siguiente pieza, pieza almacenada).\n",
    "\n",
    "   - Por ejemplo, si tienes cinco acciones posibles (MI, MD, R, B, G), podr√≠as codificarlas como [1, 0, 0, 0, 0] para MI, [0, 1, 0, 0, 0] para MD, y as√≠ sucesivamente. Concatena esta representaci√≥n con el vector que describe el estado del juego.\n",
    "\n",
    "   - Respecto a la medida de distancia, la elecci√≥n de la distancia depender√° de la naturaleza de tus datos y la importancia relativa de cada caracter√≠stica. La distancia euclidiana es com√∫n, pero tambi√©n podr√≠as considerar otras m√©tricas como la distancia de Manhattan o la distancia de Minkowski.\n",
    "\n",
    "2. **Medida de Distancia para Calcular el Error:**\n",
    "   - Dado que est√°s tratando con una secuencia de acciones, la distancia entre dos secuencias puede evaluarse mediante la distancia de edici√≥n (tambi√©n conocida como distancia de Levenshtein). Esta medida cuenta el n√∫mero m√≠nimo de operaciones necesarias para transformar una secuencia en la otra, donde las operaciones son inserciones, eliminaciones o sustituciones de elementos.\n",
    "\n",
    "   - En tu caso, podr√≠as usar la distancia de edici√≥n para comparar la secuencia de acciones realizadas por el jugador con la secuencia de acciones generadas por el agente. Cuanto menor sea la distancia de edici√≥n, m√°s similares son las secuencias.\n",
    "\n",
    "   - La distancia de edici√≥n se adapta bien a comparaciones de secuencias y puede ser adecuada para evaluar el rendimiento del agente en t√©rminos de imitar la secuencia de acciones del jugador en un estado de juego dado.\n",
    "\n",
    "### Respuesta Isma\n",
    "1. ¬øComo codificar√≠as los datos para que KNN pueda funcionar correctamente y que\n",
    "medida de distancia usar√≠as?\n",
    "\n",
    "- La cuadr√≠cula con piezas seria una matriz de entrada donde valdr√≠a 1 la casilla X,Y\n",
    "esta ocupada por una pieza y 0 en caso contrario\n",
    "- La posici√≥n de la pieza actual se guardar√° como un valor real con el origen de\n",
    "coordinadas de (0,0) en la esquina inferior izquierda de la parte jugable y que ira\n",
    "de 0 a 1.\n",
    "- Usamos One-hot-encoding para guardar el identificador de la pieza guardada, la\n",
    "actual y la pr√≥xima ya que la categoria no es ordinal\n",
    "- Para saber el nivel tambien codificaremos este n√∫mero como n√∫mero real entre\n",
    "0-1 seindo 0 el nivel 0 y 1 el nivel m√°s alto posible.\n",
    "- como medida de similitud usar√≠a la distancia de Manhattan ya que en este tipo de\n",
    "problemas las diagonales no son importantes a priori (en el tetris no te puedes\n",
    "mover en diagonal)\n",
    "- Tendr√≠a una ventana temporal de acciones realizadas previamente ya que hay\n",
    "una dependencia entre las acciones realizadas anteriormente y las nuevas.\n",
    "\n",
    "2. Para saber si el agente imita correctamente al jugador, comprobamos que la\n",
    "secuencia de acciones realizadas por el agente sea similar a la del jugador para un\n",
    "estado de juego dado (El Tetris es determinista asumiendo la misma semilla\n",
    "aleatoria) De esta forma tendremos la secuencia de acciones MI|MD|R|B|MI|MI|B|G|MD|MI|MD|R|R|B.\n",
    "¬øQu√© medida de distancia utilizar√≠as para calcular el error?\n",
    "\n",
    "Usar√≠a distancia de edici√≥n. La similitud ser√≠a el n√∫mero de cambios que hacen que\n",
    "una cadena sea igual que la otra. Esta medida es m√°s representativa que una distancia\n",
    "eucl√≠dea, primero porque el valor de la clase no es ordinal y por otro lado, porque hay\n",
    "una dependencia temporal de las acciones realizadas. Si queremos imitar a la\n",
    "percepci√≥n el comportamiento del humano, debemos realizar las mismas acciones en\n",
    "le mismo orden m√°s all√° de que estas sean buenas o malas.\n",
    "\n",
    "### Claves de la respuesta\n",
    "1. Representar el estado con unos datos con sentido.\n",
    "2. Para cadenas y secuencias se usa la distancia de edici√≥n, tambi√©n llamada distancia de Levenshtein.\n",
    "Mide el n√∫mero de cambios que hay que hacer para convertir una instancia en otra (casa ‚Üí cala ‚Üí calla ‚Üí calle)\n",
    "\n",
    "## Problema 5\n",
    "Dada la siguiente tabla con los datos de entrenamiento de un algoritmo ID3 y\n",
    "utilizando la Ganancia y la Entrop√≠a\n",
    "Claro, aqu√≠ tienes el texto formateado en Markdown:\n",
    "\n",
    "Dada la siguiente tabla con los datos de entrenamiento de un algoritmo ID3 y utilizando la Ganancia y la Entrop√≠a:\n",
    "\n",
    "\\[ \\text{Entrop√≠a}(s) = \\sum_{i}^{-p_i \\cdot \\log_2{p_i}} \\]\n",
    "\n",
    "\\[ \\text{Ganancia}(S, A) = \\text{Entrop√≠a}(S) - \\sum_{v \\in V(A)} \\frac{|S_v|}{|S|} \\cdot \\text{Entrop√≠a}(S_v) \\]\n",
    "\n",
    "Donde ùëùùëñ es la probabilidad del atributo i-√©simo, S es el conjunto de todos los ejemplos\n",
    "y A el conjunto de todos los atributos y V(A) los valores de todos los atributos.\n",
    "\n",
    "| A1 | A2 | A3 | A4 | Clase |\n",
    "|----|----|----|----|-------|\n",
    "| 2  | 0  | 3  | A  | Bueno |\n",
    "| 1  | 1  | 1  | B  | Malo  |\n",
    "| 1  | 2  | 0  | B  | Bueno |\n",
    "| 0  | 2  | 1  | B  | Bueno |\n",
    "| 2  | 1  | 0  | A  | Malo  |\n",
    "| 3  | 0  | 1  | B  | Malo  |\n",
    "\n",
    "1. Calcular cu√°l ser√° el atributo que primero elegir√° ID3\n",
    "\n",
    "### Respuesta ChatGPT\n",
    "Para calcular la Ganancia de Informaci√≥n y la Entrop√≠a para decidir cu√°l atributo elegir√° primero el algoritmo ID3, sigamos los pasos. Primero, calculemos la Entrop√≠a de S (Entrop√≠a(S)) y luego la Ganancia de Informaci√≥n para cada atributo (Ganancia(S, A)):\n",
    "\n",
    "1. **Calcular Entrop√≠a(S):**\n",
    "\n",
    "\\[ \\text{Entrop√≠a}(S) = -p_{\\text{Bueno}} \\cdot \\log_2(p_{\\text{Bueno}}) - p_{\\text{Malo}} \\cdot \\log_2(p_{\\text{Malo}}) \\]\n",
    "\n",
    "\\[ p_{\\text{Bueno}} = \\frac{3}{6} \\]\n",
    "\\[ p_{\\text{Malo}} = \\frac{3}{6} \\]\n",
    "\n",
    "\\[ \\text{Entrop√≠a}(S) = -\\frac{3}{6} \\cdot \\log_2\\left(\\frac{3}{6}\\right) - \\frac{3}{6} \\cdot \\log_2\\left(\\frac{3}{6}\\right) \\]\n",
    "\n",
    "2. **Calcular Ganancia de Informaci√≥n para cada atributo (A1, A2, A3, A4):**\n",
    "\n",
    "\\[ \\text{Ganancia}(S, A) = \\text{Entrop√≠a}(S) - \\sum_{v \\in V(A)} \\frac{|S_v|}{|S|} \\cdot \\text{Entrop√≠a}(S_v) \\]\n",
    "\n",
    "   - Para A1:\n",
    "\n",
    "     \\[ |S_1| = 1, |S_2| = 2, |S_3| = 2, |S_4| = 1 \\]\n",
    "\n",
    "     \\[ \\text{Ganancia}(S, A1) = \\text{Entrop√≠a}(S)\n",
    "\n",
    "### Respuesta Isma\n",
    "\n",
    "1. ¬øQu√© atributo elegir√≠a primero el √°rbol de decisi√≥n?\n",
    "La f√≥rmula para calcular el logaritmo en base 2 se expresa como:\n",
    "\n",
    "\\[ \\log_2{N} = \\frac{\\log_b{N}}{\\log_b{2}} \\quad \\forall b \\]\n",
    "\n",
    "Por ejemplo, \\(\\log_{10}{A1} = \\frac{\\log_{2}{A1}}{\\log_{2}{10}}\\).\n",
    "\n",
    "Para el atributo A1, para la clase (Bueno) tenemos un 1. Para la clase (malo) tenemos\n",
    "0.\n",
    "\n",
    "- Para el valor de 0: \n",
    "  \\[ I_{10} = -\\frac{1}{1} \\log_2{1} - \\frac{0}{1} \\log_2{0} = 0 \\]\n",
    "- Para el valor de 1 tenemos uno de la clase malo y otro de la clase bueno:\n",
    "  \\[ I_{11} = -\\frac{1}{2} \\log_2{\\frac{1}{2}} - \\frac{1}{2} \\log_2{\\frac{1}{2}} = 1 \\]\n",
    "- Para el valor de 2 tenemos uno de la clase malo y otro de la clase bueno:\n",
    "  \\[ I_{12} = -\\frac{1}{2} \\log_2{\\frac{1}{2}} - \\frac{1}{2} \\log_2{\\frac{1}{2}} = 1 \\]\n",
    "- Para el valor de 3:\n",
    "  \\[ I_{13} = -\\frac{1}{1} \\log_2{1} - \\frac{0}{1} \\log_2{0} = 0 \\]\n",
    "\n",
    "\\[ A1 = \\frac{1}{6} \\cdot (0) + \\frac{2}{6} \\cdot 1 + \\frac{2}{6} \\cdot 1 + \\frac{1}{6} \\cdot 0 = \\frac{4}{6} = 0.66 \\]\n",
    "\n",
    "\\[ I_{20} + I_{21} + I_{22} = \\frac{2}{6} \\cdot 1 + \\frac{2}{6} \\cdot 0 + \\frac{2}{6} \\cdot 0 = \\frac{2}{6} \\]\n",
    "\n",
    "\\[ A2 = \\frac{1}{3} = \\frac{2}{6} \\]\n",
    "\n",
    "\\[ I_{30} + I_{31} + I_{33} = \\frac{2}{6} \\cdot 1 + \\frac{3}{6} \\cdot 0.924 + \\frac{1}{6} \\cdot 0 = 0.33 + 0.462 \\]\n",
    "\n",
    "\\[ A3 = \\frac{5}{6} = \\frac{2}{6} \\]\n",
    "\n",
    "\\[ I_{4A} + I_{4B} = \\frac{2}{6} \\cdot 1 + \\frac{4}{6} \\cdot 1 = \\frac{5}{6} \\]\n",
    "\n",
    "\\[ A4 = 1 = \\frac{2}{6} \\]\n",
    "\n",
    "El atributo que el √°rbol de decisi√≥n elegir√≠a primero ser√≠a A2, ya que tiene la menor impureza entre los atributos considerados.\n",
    "\n",
    "### Claves de la respuesta\n",
    "Copiar y rezar xd\n",
    "\n",
    "## Problema 6\n",
    "Si quiero extraer las caracter√≠sticas de una imagen para poder aplicar un algoritmo de\n",
    "ML sobre una versi√≥n reducida de dicha imagen ¬øQu√© t√©cnicas puedo aplicar y que\n",
    "ventajas e inconvenientes tiene cada una?\n",
    "\n",
    "### Respuesta ChatGPT\n",
    "Para extraer caracter√≠sticas de una imagen antes de aplicar un algoritmo de Machine Learning sobre una versi√≥n reducida, puedes considerar varias t√©cnicas. Aqu√≠ hay algunas opciones comunes:\n",
    "\n",
    "1. **Histogramas de Color:**\n",
    "   - **Ventajas:**\n",
    "     - Simple y r√°pido de calcular.\n",
    "     - Puede proporcionar informaci√≥n sobre la distribuci√≥n de colores en la imagen.\n",
    "   - **Inconvenientes:**\n",
    "     - No captura la estructura espacial de la imagen.\n",
    "\n",
    "2. **Texturas:**\n",
    "   - **Ventajas:**\n",
    "     - Captura la informaci√≥n sobre la variaci√≥n local de intensidades en la imagen.\n",
    "     - √ötil para detectar patrones repetitivos.\n",
    "   - **Inconvenientes:**\n",
    "     - Puede ser computacionalmente costoso.\n",
    "     - Requiere m√©todos m√°s avanzados para su c√°lculo, como matrices de co-ocurrencia.\n",
    "\n",
    "3. **Descriptores de Forma:**\n",
    "   - **Ventajas:**\n",
    "     - Describe la forma y la geometr√≠a de los objetos en la imagen.\n",
    "   - **Inconvenientes:**\n",
    "     - Sensible a la rotaci√≥n y escala.\n",
    "\n",
    "4. **Caracter√≠sticas de Frecuencia (Transformada de Fourier, Transformada Wavelet):**\n",
    "   - **Ventajas:**\n",
    "     - Puede proporcionar informaci√≥n sobre patrones en diferentes escalas.\n",
    "   - **Inconvenientes:**\n",
    "     - Puede ser computacionalmente intensivo.\n",
    "     - Requiere conocimiento sobre la interpretaci√≥n de los resultados.\n",
    "\n",
    "5. **Descriptores Locales (por ejemplo, SIFT, SURF, ORB):**\n",
    "   - **Ventajas:**\n",
    "     - Capturan caracter√≠sticas locales y son robustos a las transformaciones.\n",
    "   - **Inconvenientes:**\n",
    "     - Pueden ser computacionalmente costosos.\n",
    "     - Requieren m√°s recursos y tiempo de c√≥mputo.\n",
    "\n",
    "6. **Redes Neuronales Convolucionales (CNN):**\n",
    "   - **Ventajas:**\n",
    "     - Aprenden autom√°ticamente caracter√≠sticas jer√°rquicas.\n",
    "     - Eficientes para tareas de visi√≥n por computadora.\n",
    "   - **Inconvenientes:**\n",
    "     - Requieren grandes cantidades de datos de entrenamiento.\n",
    "     - Pueden ser m√°s complejas y dif√≠ciles de interpretar.\n",
    "\n",
    "La elecci√≥n de la t√©cnica depender√° del contexto espec√≠fico de tu aplicaci√≥n, la cantidad de datos disponibles, la complejidad del problema y los recursos computacionales disponibles. En muchos casos, una combinaci√≥n de varias t√©cnicas puede proporcionar la mejor representaci√≥n de las caracter√≠sticas de la imagen.\n",
    "\n",
    "### Respuesta Isma\n",
    "-Escalar la imagen usando un algoritmo de escalado: m√©todo conocido y r√°pido\n",
    "desventaja, no permite extraer informaci√≥n m√°s all√° de concentrar la informaci√≥n\n",
    "en menos pixeles\n",
    "- PCA:\n",
    "- Autoencoder: Permite extraer un resumen de la red m√°s complejo y m√°s rico,\n",
    "pero se necesita un gran volumen de datos para entrenar\n",
    "- Convolutional networks: permite detectar caracter√≠sticas concretas dentro de\n",
    "una imagen. Solo detecta una caracter√≠stica concreta por cada capa convolucional.\n",
    "no reduce la dimensionalidad tanto como autoenconder y pca\n",
    "\n",
    "### Respuesta Diego\n",
    "- Escalar la imagen usando un algoritmo de escalado:\n",
    "    - Ventajas: m√©todo conocido y r√°pido.\n",
    "    - Desventajas: no permite extraer informaci√≥n m√°s all√° de concentrar la\n",
    "informaci√≥n en menos p√≠xeles.\n",
    "- PCA:\n",
    "    - Ventajas: Reduce el n√∫mero de variables manteniendo la mayor parte de\n",
    "la informaci√≥n. Es √∫til para la visualizaci√≥n de datos y puede mejorar el\n",
    "rendimiento de los algoritmos de ML al eliminar el ruido y las\n",
    "caracter√≠sticas irrelevantes.\n",
    "    - Desventajas: La reducci√≥n puede resultar en la p√©rdida de informaci√≥n\n",
    "importante. La interpretaci√≥n de los componentes principales puede ser\n",
    "dif√≠cil.\n",
    "- Redes neuronales Convolucionales (CNN):\n",
    "    - Ventajas: Excelente para extraer caracter√≠sticas jer√°rquicas\n",
    "autom√°ticamente. Muy efectivo en tareas de reconocimiento y\n",
    "clasificaci√≥n de im√°genes.\n",
    "    - Desventajas: Requiere una gran cantidad de datos y recursos\n",
    "computacionales. La interpretaci√≥n de las caracter√≠sticas extra√≠das\n",
    "puede ser compleja.\n",
    "- Autoencoders:\n",
    "    - Ventajas: Aprenden a comprimir y descomprimir datos, capturando\n",
    "caracter√≠sticas esenciales. √ötil para reducci√≥n de dimensionalidad y\n",
    "aprendizaje no supervisado.\n",
    "    - Desventajas: Puede ser dif√≠cil entrenar y ajustar. La calidad de las\n",
    "caracter√≠sticas extra√≠das depende en gran medida de la arquitectura y\n",
    "los datos de entrenamiento.\n",
    "\n",
    "### Claves de la respuesta\n",
    "Data Agmentation, escalar la muestra para reducir el tama√±o (manualmente o con PCA),\n",
    "las redes convolucionales se especializan en imagenes. El autoencoder extrae\n",
    "las caracter√≠sticas de una imagen codificadas en muchos menos componentes.\n",
    "\n",
    "## Problema 7\n",
    "A priori (ya que no se est√° totalmente seguro hasta no implementarlos), ¬øQu√©\n",
    "algoritmo clasificar√≠a mejor un problema que no es linealmente separable? Explica\n",
    "porqu√©.\n",
    "- Un √°rbol de decisi√≥n\n",
    "- Una Red de neuronas profunda compuesta √∫nicamente por capas\n",
    "convolucionales.\n",
    "- Un Perceptr√≥n multicapa con funci√≥n de activaci√≥n ReLu\n",
    "\n",
    "### Respuesta ChatGPT\n",
    "En un problema que no es linealmente separable, es probable que una Red de Neuronas Profunda (DNN) compuesta √∫nicamente por capas convolucionales tenga un mejor rendimiento que un √°rbol de decisi√≥n o un perceptr√≥n multicapa con funci√≥n de activaci√≥n ReLu. Aqu√≠ est√°n las razones:\n",
    "\n",
    "1. **√Årbol de Decisi√≥n:**\n",
    "   - *Ventajas:*\n",
    "     - Buen rendimiento en problemas con separaci√≥n lineal o estructura jer√°rquica simple.\n",
    "     - Interpretabilidad, ya que puede proporcionar reglas de decisi√≥n f√°ciles de entender.\n",
    "   - *Inconvenientes:*\n",
    "     - Limitado en la capacidad para aprender patrones complejos y no lineales.\n",
    "     - Sensible a variaciones peque√±as en los datos de entrenamiento.\n",
    "\n",
    "2. **Red de Neuronas Profunda (Solo Capas Convolucionales):**\n",
    "   - *Ventajas:*\n",
    "     - Capaz de aprender representaciones jer√°rquicas y patrones complejos.\n",
    "     - Robusta para manejar datos no lineales y problemas de visi√≥n por computadora.\n",
    "     - Puede aprender caracter√≠sticas espaciales locales a trav√©s de las capas convolucionales.\n",
    "   - *Inconvenientes:*\n",
    "     - Requiere grandes cantidades de datos de entrenamiento.\n",
    "     - Puede ser computacionalmente costoso y requerir recursos de hardware.\n",
    "\n",
    "3. **Perceptr√≥n Multicapa con Funci√≥n de Activaci√≥n ReLu:**\n",
    "   - *Ventajas:*\n",
    "     - Puede aprender representaciones no lineales.\n",
    "     - Bien adaptado para problemas complejos.\n",
    "     - Eficiente en t√©rminos computacionales.\n",
    "   - *Inconvenientes:*\n",
    "     - No es tan eficaz como las CNN en la captura de caracter√≠sticas espaciales locales.\n",
    "     - Puede tener dificultades con datos de alta dimensionalidad, como im√°genes.\n",
    "\n",
    "En resumen, una red de neuronas profundas, especialmente aquellas dise√±adas espec√≠ficamente para problemas de visi√≥n por computadora con capas convolucionales, generalmente tiene un rendimiento superior en problemas no lineales y en la clasificaci√≥n de datos no linealmente separables, como en el caso de im√°genes. Sin embargo, la elecci√≥n del algoritmo tambi√©n depende de otros factores, como la disponibilidad de datos de entrenamiento, el tama√±o del conjunto de datos y los recursos computacionales disponibles.\n",
    "\n",
    "### Respuesta Isma\n",
    "Un Perceptr√≥n multicapa con funci√≥n de activaci√≥n ReLu ya que no es una funci√≥n de\n",
    "activaci√≥n lineal\n",
    "\n",
    "### Respuesta Diego\n",
    "Mientras que los √°rboles de decisi√≥n y las CNN tienen sus fortalezas en ciertos tipos de\n",
    "datos y problemas espec√≠ficos, un Perceptr√≥n Multicapa con funci√≥n de activaci√≥n\n",
    "ReLu generalmente ofrece una mayor flexibilidad y capacidad para modelar problemas\n",
    "complejos y no lineales. Esto se debe a su arquitectura de m√∫ltiples capas y a la\n",
    "capacidad de la funci√≥n ReLu para introducir no linealidades, lo que permite que el\n",
    "MLP aprenda patrones complejos y relaciones intrincadas en los datos.\n",
    "\n",
    "### Clave de la respuesta\n",
    "Decir redes convolucionales si es para imagen, pero como te esta especificando relu quieres elegir esa.\n",
    "\n",
    "## Problema 8\n",
    "Tenemos un problema de clasificaci√≥n que tiene 5 clases. Queremos dise√±ar una red\n",
    "de neuronas, pero no tenemos claro cual ser√° el modelo a elegir. Lo que si queremos\n",
    "es que la salida de la red nos devuelva la probabilidad de que un elemento pertenezca\n",
    "a cada una de las clases. Describe como ser√≠a la capa de salida de la red neuronal,\n",
    "cuantas neuronas de salida y de que tipo ser√≠a.\n",
    "\n",
    "### Respuesta ChatGPT\n",
    "En un problema de clasificaci√≥n con cinco clases en el que deseas obtener la probabilidad de pertenencia a cada clase, la capa de salida de la red neuronal generalmente constar√≠a de cinco neuronas. Adem√°s, para lograr la salida de probabilidades, se utilizar√≠a una funci√≥n de activaci√≥n softmax.\n",
    "\n",
    "**Capa de Salida:**\n",
    "- **N√∫mero de Neuronas:** Cinco neuronas, una para cada clase.\n",
    "- **Funci√≥n de Activaci√≥n:** Softmax.\n",
    "\n",
    "La funci√≥n de activaci√≥n softmax toma un vector de entrada y produce un vector de salida donde cada elemento representa la probabilidad de que la entrada pertenezca a una clase espec√≠fica. La funci√≥n softmax se define como:\n",
    "\n",
    "\\[ \\text{Softmax}(z)_i = \\frac{e^{z_i}}{\\sum_{j=1}^{C} e^{z_j}} \\]\n",
    "\n",
    "donde \\( z \\) es el vector de entrada, \\( C \\) es el n√∫mero de clases y \\( i \\) es el √≠ndice de la clase.\n",
    "\n",
    "En resumen, la capa de salida de la red neuronal se configurar√≠a para producir una distribuci√≥n de probabilidad sobre las cinco clases, permiti√©ndote interpretar la salida como las probabilidades de pertenencia a cada clase para un dato de entrada dado. La clase con la probabilidad m√°s alta ser√≠a la predicci√≥n final de la red neuronal.\n",
    "\n",
    "### Respuesta Isma\n",
    "para 5 salidas tendr√≠amos 5 neuronas y la funci√≥n de activaci√≥n ser√≠a softmax.\n",
    "\n",
    "### Respuesta Diego\n",
    "Deber√≠a haber 5 neuronas en la capa de salida, una por cada clase. La funci√≥n\n",
    "de activaci√≥n m√°s adecuada para este caso es la funci√≥n Softmax. Mientras que\n",
    "funciones como la sigmoide comprimen las salidas entre 0 y 1, la Softmax es\n",
    "ideal para la clasificaci√≥n multiclase porque no solo comprime las salidas entre\n",
    "0 y 1, sino que tambi√©n asegura que la suma total de las salidas\n",
    "(probabilidades) de todas las neuronas en la capa sea igual a 1. Esto convierte\n",
    "efectivamente las salidas en una distribuci√≥n de probabilidad\n",
    "\n",
    "### Claves de la respuesta\n",
    "Softmax sirve para dar probabilidades.\n",
    "\n",
    "## Problema 9\n",
    "1. ¬øD√≥nde aplicar√≠as clustering? Pon un ejemplo.\n",
    "2. Si utilizas K-Means, ¬øC√≥mo podr√≠as determinar el valor de K?\n",
    "\n",
    "### Respuesta ChatGPT\n",
    "1. **Aplicaci√≥n de Clustering:**\n",
    "   - **Ejemplo:** Imagina que tienes un conjunto de datos de clientes de un centro comercial y deseas agruparlos en segmentos basados en su comportamiento de compra. Aqu√≠, podr√≠as aplicar t√©cnicas de clustering para identificar grupos de clientes similares en t√©rminos de patrones de compra. Esto te permitir√≠a personalizar estrategias de marketing o servicios para cada segmento, mejorando as√≠ la satisfacci√≥n del cliente y la eficacia de las estrategias comerciales.\n",
    "\n",
    "2. **Determinaci√≥n del Valor de K en K-Means:**\n",
    "   - **M√©todo del Codo (Elbow Method):** Una t√©cnica com√∫n para determinar el valor √≥ptimo de K en K-Means es el m√©todo del codo. Consiste en ejecutar el algoritmo K-Means con diferentes valores de K y calcular la suma de las distancias cuadradas intra-cluster (inertia) para cada valor de K. Luego, se busca el \"codo\" en la gr√°fica de la inercia en funci√≥n de K. El codo representa el punto donde agregar m√°s clusters no proporciona una mejora significativa en la inercia. Ese valor de K se elige como el n√∫mero √≥ptimo de clusters.\n",
    "\n",
    "   - **Silhouette Score:** Otra m√©trica utilizada es el Silhouette Score, que mide cu√°n similar es un objeto a su propio cl√∫ster en comparaci√≥n con otros cl√∫steres. Se busca el valor de K que maximiza el Silhouette Score.\n",
    "\n",
    "   - **M√©todos Jer√°rquicos:** Si se prefiere un enfoque jer√°rquico, se puede utilizar un dendrograma para visualizar la estructura jer√°rquica del clustering y tomar decisiones sobre el n√∫mero √≥ptimo de clusters.\n",
    "\n",
    "La elecci√≥n del valor de K a menudo implica un equilibrio entre la simplicidad del modelo y su capacidad para representar adecuadamente la estructura subyacente de los datos. La interpretaci√≥n del problema y la evaluaci√≥n de diversas m√©tricas pueden ayudar en la toma de decisiones.\n",
    "\n",
    "### Respuesta Diego\n",
    "1. ¬øD√≥nde aplicar√≠as clustering? Pon un ejemplo.\n",
    "- El clustering es una t√©cnica de aprendizaje no supervisado que se utiliza para\n",
    "agrupar datos similares en conjuntos o clusters. Se aplica en una amplia\n",
    "variedad de campos y situaciones para descubrir patrones y estructuras en\n",
    "datos. Aqu√≠ tienes un ejemplo de d√≥nde podr√≠as aplicar el clustering:\n",
    "Ejemplo: Segmentaci√≥n de clientes en una tienda en l√≠nea\n",
    "Imagina que tienes una tienda en l√≠nea que vende una variedad de productos y\n",
    "deseas comprender mejor a tus clientes para ofrecerles una experiencia de\n",
    "compra m√°s personalizada y efectiva. Puedes aplicar clustering de la siguiente\n",
    "manera:\n",
    "1. Recopilaci√≥n de datos: Recolecta datos sobre tus clientes, como\n",
    "historiales de compras, categor√≠as de productos que han comprado,\n",
    "frecuencia de compra, gasto promedio, etc.\n",
    "2. Selecci√≥n de caracter√≠sticas: Selecciona las caracter√≠sticas relevantes de\n",
    "los clientes que deseas utilizar en el proceso de clustering, como la\n",
    "frecuencia de compra y el gasto promedio.\n",
    "3. Aplicaci√≥n de clustering: Utiliza un algoritmo de clustering, como\n",
    "K-Means o Hierarchical Clustering, para agrupar a tus clientes en\n",
    "segmentos similares en funci√≥n de las caracter√≠sticas seleccionadas.\n",
    "Cada grupo representar√° un segmento de clientes con comportamientos\n",
    "de compra similares.\n",
    "4. An√°lisis de resultados: Analiza los resultados del clustering para\n",
    "identificar patrones y caracter√≠sticas distintivas de cada grupo de\n",
    "clientes. Por ejemplo, podr√≠as descubrir que un grupo de clientes realiza\n",
    "compras frecuentes pero de bajo valor, mientras que otro grupo realiza\n",
    "compras espor√°dicas pero de alto valor.\n",
    "5. Personalizaci√≥n: Utiliza la informaci√≥n obtenida de la segmentaci√≥n\n",
    "para personalizar las ofertas, promociones y recomendaciones de\n",
    "productos para cada grupo de clientes. Por ejemplo, podr√≠as enviar\n",
    "ofertas especiales a clientes que realizan compras frecuentes pero de\n",
    "bajo valor para incentivar compras m√°s grandes.\n",
    "2. Si utilizas K-Means, ¬øC√≥mo podr√≠as determinar el valor de K?\n",
    "- Se podr√≠a utilizar el m√©todo del codo. Pasos:\n",
    "- Ejecutar K-Means: Se ejecuta el algoritmo K-Means en el conjunto de\n",
    "datos para un rango de valores de K (por ejemplo, K=1 a K=10).\n",
    "- Calcular la Varianza: Para cada K, se calcula la suma de las distancias al\n",
    "cuadrado de los puntos a su centroide m√°s cercano, conocida como la\n",
    "varianza dentro de los cl√∫steres o WCSS (Within-Cluster Sum of\n",
    "Squares).\n",
    "- Graficar los Resultados: Se crea una gr√°fica de l√≠nea donde el eje X\n",
    "representa el n√∫mero de cl√∫steres (K) y el eje Y representa el valor de la\n",
    "varianza correspondiente (WCSS).\n",
    "- Identificar el codo: Se busca el punto en la gr√°fica donde el descenso de\n",
    "la varianza/WCSS cambia de ser r√°pido a ser lento, lo que indica que\n",
    "agregar m√°s cl√∫steres no mejora significativamente la varianza dentro\n",
    "del cl√∫ster. Este punto se asemeja a un \"codo\" en la gr√°fica.\n",
    "\n",
    "### Claves de la respuesta\n",
    "Quiere K-means, tecnica del codo, coef. de silhouette y el ejemplo de los clientes.\n",
    "\n",
    "## Problema 10\n",
    "Dado los siguientes datos:\n",
    "```\n",
    "| A1 | A2 | A3 | A4 |\n",
    "|----|----|----|----|\n",
    "| 2  | 0  | 3  | 2  |\n",
    "| 1  | 1  | 1  | 0  |\n",
    "| 2  | 0  | 2  | 2  |\n",
    "| 0  | 2  | 1  | 1  |\n",
    "| 2  | 1  | 0  | 1  |\n",
    "| 2  | 0  | 3  | 0  |\n",
    "```\n",
    "Describe que clases generar√≠a un algoritmo de clustering aglomerativo con distancia\n",
    "de Manhattan\n",
    "\n",
    "### Respuesta ChatGPT\n",
    "Para aplicar un algoritmo de clustering aglomerativo con distancia de Manhattan, se inicia considerando cada punto como un cluster individual y se fusionan iterativamente los clusters m√°s cercanos. La distancia entre dos clusters se mide seg√∫n la distancia de Manhattan entre sus puntos m√°s cercanos.\n",
    "\n",
    "Vamos a describir el proceso paso a paso para los datos proporcionados:\n",
    "\n",
    "**Datos:**\n",
    "```\n",
    "| A1 | A2 | A3 | A4 |\n",
    "|----|----|----|----|\n",
    "| 2  | 0  | 3  | 2  |\n",
    "| 1  | 1  | 1  | 0  |\n",
    "| 2  | 0  | 2  | 2  |\n",
    "| 0  | 2  | 1  | 1  |\n",
    "| 2  | 1  | 0  | 1  |\n",
    "| 2  | 0  | 3  | 0  |\n",
    "```\n",
    "\n",
    "**Paso 1:** Calcular las distancias entre todos los pares de puntos utilizando la distancia de Manhattan.\n",
    "\n",
    "**Paso 2:** Fusionar los dos clusters m√°s cercanos en un nuevo cluster. Continuar este proceso hasta que todos los puntos est√©n en un solo cluster.\n",
    "\n",
    "**Posibles pasos intermedios (ejemplo simplificado):**\n",
    "```\n",
    "| Cluster 1 | Cluster 2 | Distancia |\n",
    "|-----------|-----------|-----------|\n",
    "| 1         | 2         | 3         |\n",
    "| 3         | 6         | 4         |\n",
    "| 4         | 5         | 2         |\n",
    "```\n",
    "\n",
    "Despu√©s de cada paso, los clusters se fusionan seg√∫n la distancia m√≠nima. Por ejemplo, en el primer paso, los puntos 1 y 2 se fusionan en un nuevo cluster. En el segundo paso, los clusters 3 y 6 se fusionan, y as√≠ sucesivamente.\n",
    "\n",
    "**Resultado Final:**\n",
    "```\n",
    "| Cluster Final |\n",
    "|---------------|\n",
    "| 1             |\n",
    "| 2             |\n",
    "| 3             |\n",
    "| 4             |\n",
    "| 5             |\n",
    "| 6             |\n",
    "```\n",
    "\n",
    "En este resultado, cada n√∫mero representa un punto del conjunto de datos. El algoritmo de clustering aglomerativo ha agrupado los puntos en clusters bas√°ndose en la distancia de Manhattan, y los clusters finales est√°n representados en la tabla \"Cluster Final\". Cada cluster representa una clase obtenida mediante el proceso de clustering aglomerativo.\n",
    "\n",
    "### Respuesta Diego \n",
    "1¬∫ Restamos las filas que parecen similares para obtener la fila con menos distancia\n",
    "- absoluto(F0 - F2) = 0 0 1 0\n",
    "2¬∫ Sumamos todos los valores\n",
    "- 0 + 0 + 1 + 0 = 1\n",
    "3¬∫ Como es la que menos distancia a dado entonces, usamos las filas F0 y F2 para\n",
    "calcular el punto medio entre las 2\n",
    "- (F0 + F2)/2 = (4 0 5 4)/2 = 2 0 2.5 2\n",
    "4¬∫ Quitamos las filas usadas F0 y F2 y metemos la fila fusionada donde queramos,\n",
    "quedando:\n",
    "A1 A2 A3 A4\n",
    "2 0 2.5 2\n",
    "2 0 3 2\n",
    "1 1 1 0\n",
    "2 0 2 2\n",
    "0 2 1 1\n",
    "2 1 0 1\n",
    "2 0 3 0\n",
    "\n",
    "### Claves de la respuesta\n",
    "Copiar y rezar\n",
    "\n",
    "## Problema 11\n",
    "Tenemos un NPC en un videojuego de lucha y queremos que aprenda a luchar de\n",
    "forma eficiente contra una IA ya programada. No disponemos de un dataset con\n",
    "informaci√≥n de partidas previas. Qu√© algoritmo utilizar√≠as y describe brevemente y de\n",
    "forma aproximada como lo implementar√≠as.\n",
    "\n",
    "### Respuesta ChatGPT\n",
    "Para abordar el problema de hacer que un NPC aprenda a luchar de manera eficiente contra una IA ya programada sin un conjunto de datos previo, podr√≠as considerar el uso de algoritmos de aprendizaje por refuerzo (RL), y en particular, podr√≠as implementar un enfoque basado en Q-Learning.\n",
    "\n",
    "**Algoritmo a utilizar: Q-Learning**\n",
    "\n",
    "**Descripci√≥n aproximada de la implementaci√≥n:**\n",
    "\n",
    "1. **Definici√≥n del entorno:**\n",
    "   - Identifica las acciones posibles que el NPC puede realizar durante una pelea (moverse, atacar, bloquear, etc.).\n",
    "   - Define el estado del entorno, que podr√≠a incluir informaci√≥n sobre la posici√≥n del NPC, la salud del NPC y del oponente, la distancia entre ellos, etc.\n",
    "\n",
    "2. **Estructura de Q-Table:**\n",
    "   - Crea una tabla Q que represente el valor de cada par (estado, acci√≥n). Inicializa la tabla con valores arbitrarios o todos a cero.\n",
    "\n",
    "3. **Exploraci√≥n y explotaci√≥n:**\n",
    "   - Implementa una estrategia para equilibrar la exploraci√≥n del espacio de acciones y la explotaci√≥n de acciones conocidas. Esto podr√≠a ser epsilon-greedy, donde el NPC elige una acci√≥n aleatoria con probabilidad epsilon y, de lo contrario, elige la acci√≥n con el valor Q m√°s alto.\n",
    "\n",
    "4. **Iteraciones de aprendizaje:**\n",
    "   - En cada iteraci√≥n del juego, el NPC realiza una acci√≥n en el entorno seg√∫n su estrategia (exploraci√≥n/explotaci√≥n).\n",
    "   - Observa la recompensa obtenida y la nueva observaci√≥n del entorno despu√©s de la acci√≥n.\n",
    "   - Actualiza el valor Q para la acci√≥n y estado actual utilizando la f√≥rmula de actualizaci√≥n de Q-Learning:\n",
    "     \\[ Q(s, a) \\leftarrow (1 - \\alpha) \\cdot Q(s, a) + \\alpha \\cdot (r + \\gamma \\cdot \\max_{a'} Q(s', a')) \\]\n",
    "     donde \\( \\alpha \\) es la tasa de aprendizaje y \\( \\gamma \\) es el factor de descuento.\n",
    "\n",
    "5. **Entrenamiento continuo:**\n",
    "   - Repite las iteraciones de aprendizaje durante un n√∫mero significativo de partidas para permitir que el NPC mejore su estrategia.\n",
    "\n",
    "6. **Evaluaci√≥n y ajuste:**\n",
    "   - Eval√∫a el rendimiento del NPC contra la IA programada y ajusta los hiperpar√°metros (tasa de aprendizaje, factor de descuento, epsilon) seg√∫n sea necesario.\n",
    "\n",
    "Es importante se√±alar que la implementaci√≥n real depender√° del entorno espec√≠fico del juego y de los detalles de la IA programada con la que est√°s trabajando. Adem√°s, el √©xito de este enfoque puede depender de la complejidad del juego y de c√≥mo se define el espacio de estado y acciones.\n",
    "\n",
    "### Claves de la respuesta\n",
    "Quiere que le hables de aprendizaje por refuerzo y Q-Learning\n",
    "\n",
    "## Problema 12\n",
    "¬øQu√© podemos hacer si el espacio de estados de un algoritmo de Q-Learning es\n",
    "demasiado grande? Razona la respuestae indica si se te ocurre al menos dos posibles\n",
    "soluciones.\n",
    "\n",
    "### Respuesta ChatGPT\n",
    "Cuando el espacio de estados de un algoritmo de Q-Learning es demasiado grande, puede resultar ineficiente o incluso impracticable explorar y almacenar los valores Q para cada par estado-acci√≥n. Aqu√≠ hay dos posibles soluciones para abordar este problema:\n",
    "\n",
    "1. **Discretizaci√≥n de los estados:**\n",
    "   - Una soluci√≥n com√∫n es discretizar el espacio de estados. En lugar de considerar cada valor √∫nico en el espacio de estados, agrupa o discretiza las observaciones en intervalos m√°s grandes. Esto reduce la complejidad del espacio de estados y permite construir y actualizar una tabla Q m√°s manejable. Sin embargo, esta t√©cnica puede llevar a la p√©rdida de informaci√≥n y a una aproximaci√≥n menos precisa del valor Q en algunos casos.\n",
    "\n",
    "2. **Uso de aproximadores de funci√≥n (Funciones Q Aproximadoras):**\n",
    "   - En lugar de almacenar todos los valores Q en una tabla, puedes utilizar aproximadores de funci√≥n, como redes neuronales, para estimar los valores Q. Las funciones Q aproximadoras pueden generalizar a partir de un conjunto limitado de ejemplos y proporcionar estimaciones para estados no vistos anteriormente. Esto es particularmente √∫til cuando el espacio de estados es continuo o muy grande. Al utilizar t√©cnicas como el aprendizaje profundo (Deep Q Networks - DQN), la red neuronal puede aprender representaciones m√°s ricas y generalizadas del espacio de estados.\n",
    "\n",
    "Ambas soluciones tienen sus ventajas y desventajas. La elecci√≥n entre ellas depender√° del contexto espec√≠fico del problema y de las caracter√≠sticas del entorno. La discretizaci√≥n puede ser m√°s adecuada para espacios de estados m√°s simples, mientras que el uso de funciones Q aproximadoras, como DQN, puede ser m√°s efectivo en entornos con espacios de estados m√°s complejos y continuos.\n",
    "\n",
    "### Claves de la respuesta\n",
    "Las limitaciones de Q-Learning son que el espacio de estados debe ser finito, ya que es\n",
    "muy complicado que la b√∫squeda encuentre una pol√≠tica √≥ptima si no lo es. Aun as√≠, es\n",
    "posible que los resultados no sean muy buenos. \n",
    "\n",
    "1. Se puede hacer una aproximaci√≥n mixta\n",
    "aprendiendo la tabla Q con aprendizaje supervisado para encontrar m√°s f√°cilmente la\n",
    "soluci√≥n.\n",
    "\n",
    "2. Otra aproximaci√≥n para aprender la\n",
    "tabla Q es sin un modelo. Deep QLearning (DQN) utiliza esta\n",
    "aproximaci√≥n y es la base de\n",
    "AlphaZero y AlphaStar de\n",
    "DeepMind. DQN sustituye la tabla\n",
    "Q por una red neuronal profunda,\n",
    "que predice el valor de Q para\n",
    "todos los posibles estados.\n",
    "Estas versiones son m√°s inestables,\n",
    "los valores de Q oscilan mucho y se requiere una gran cantidad de datos para que\n",
    "converjan. Se usa la ecuaci√≥n de Bellman para calcular los valores estimados y luego\n",
    "entrenar la red con ellos.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
