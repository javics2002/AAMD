{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hoja de Ejercicios y Problemas tipo examen 2\n",
    "Ismael Sagredo Olivenza\n",
    "Colaboración en este material de Belén Díaz Agudo y otros profesores de ISIA\n",
    "## Problema 01\n",
    "Tenemos un dataset con datos almacenados sobre las precipitaciones desde hace 10\n",
    "años y queremos predecir el nivel de precipitación en el futuro en función del dia del\n",
    "año (entero), la humedad (real), la cantidad de nubosidad (baja, media, alta), la\n",
    "temperatura (real) y la presión atmosférica (real).\n",
    "Hemos aplicado diferentes técnicas de Machine Learning y nos ha generado los\n",
    "siguientes resultados de accuracy:\n",
    "\n",
    "- KNN: K=5, 88% distancia euclídea.\n",
    "- Decision Tree: 90%, profundidad del árbol 5.\n",
    "- Random Forest: 98%\n",
    "- Perceptrón Multicapa: 10 neuronas ocultas en la primera capa y 5 en la segunda,\n",
    "factor de aprendiszaje de 0,2, valores normalizados 0-1: 90%\n",
    "\n",
    "A los investigadores les ha sorprendido que el perceptrón multicapa de resultados tan\n",
    "bajos.\n",
    "\n",
    "1. ¿Qué podriamos hacer para mejorar los resultados del perceptrón?\n",
    "2. Con los datos del ejercicio, razona cual sería el modelo que elegirías.\n",
    "3. En KNN el valor categórico ha sido codificado como 0, 1, 2 y el resto de atributos\n",
    "para calcular la diferencia se realizan restando sus valores sin ninguna\n",
    "transformación. ¿Cómo podríamos mejorar KNN para conseguir mejores\n",
    "resultados?\n",
    "\n",
    "### Respuesta ChatGPT\n",
    "1. Para mejorar los resultados del perceptrón multicapa, podríamos considerar las siguientes estrategias:\n",
    "   - Ajustar la arquitectura de la red: Experimentar con diferentes configuraciones de capas y unidades ocultas puede influir significativamente en el rendimiento del perceptrón.\n",
    "   - Tuning de hiperparámetros: Ajustar el factor de aprendizaje, el número de épocas y otros hiperparámetros del modelo puede mejorar la convergencia y el rendimiento general.\n",
    "   - Normalización de datos: Asegurarse de que los datos estén correctamente normalizados puede ser crucial para el rendimiento del perceptrón multicapa. Asegúrate de que todas las características estén en una escala similar (por ejemplo, entre 0 y 1).\n",
    "   - Regularización: Introducir técnicas de regularización como la penalización L1 o L2 puede ayudar a prevenir el sobreajuste y mejorar la generalización del modelo.\n",
    "\n",
    "2. Basándonos en los resultados proporcionados:\n",
    "   - El modelo Random Forest muestra el mayor rendimiento con un 98% de precisión, lo que sugiere una buena capacidad de generalización y robustez.\n",
    "   - El Decision Tree también tiene un rendimiento sólido con un 90% de precisión.\n",
    "   - KNN tiene un rendimiento aceptable, pero puede beneficiarse de ajustes en la elección de K y la métrica de distancia.\n",
    "   - El Perceptrón Multicapa, a pesar de su rendimiento más bajo del 90%, podría mejorarse mediante la exploración de las estrategias mencionadas anteriormente.\n",
    "\n",
    "3. Para mejorar KNN y obtener mejores resultados, podríamos considerar:\n",
    "   - Optimización de K: Experimentar con diferentes valores de K para encontrar el óptimo para el conjunto de datos particular.\n",
    "   - Selección de métrica de distancia: Probar otras métricas de distancia además de la distancia euclidiana, como la distancia de Mahalanobis o la distancia de Minkowski.\n",
    "   - Normalización de atributos: Normalizar los atributos puede ser crucial en KNN, ya que las diferencias en la escala de los atributos pueden afectar significativamente a las distancias calculadas.\n",
    "   - Evaluación de ponderación: Algunas implementaciones de KNN permiten ponderar las contribuciones de los vecinos en función de su distancia; experimentar con esto puede mejorar el rendimiento.\n",
    "\n",
    "### Respuesta Isma\n",
    "1. ¿Qué podriamos hacer para mejorar los resultados del perceptrón?\n",
    "\n",
    "El factor de aprendizaje quizás esté muy alto, podríamos reentrenar la red con otro\n",
    "factor de aprendizaje. Tambien podríamos modificar la arquitectura de la red o\n",
    "seleccionar los atributos\n",
    "\n",
    "2. Con los datos del ejercicio, razona cual sería el modelo que elegirías.\n",
    "\n",
    "La respuesta peude ser variada y si está argumentada sería correcta. Por un lado\n",
    "podemos pensar que un 90% es suficiente y elegir arboles de decisión por ser un\n",
    "algoritmo de caja blanca. Tenemos que tener en cuenta que saber si va a llover o no es\n",
    "algo que tiene importancia para hoteles o para saber si te vas de vacaciones o no, pero\n",
    "si 9 de cada 10 veces se va a acertar, no es un mal rendimiento. Si lo que queremos es\n",
    "maximizar la precisión usaríamos random forest, pero tenemos que ser conscientes\n",
    "que perdemos explicabilidad.\n",
    "\n",
    "3. En KNN el valor categórico ha sido codificado como 0, 1, 2 y el resto de atributos\n",
    "para calcular la diferencia se realizan restando sus valores sin ninguna\n",
    "transformación. ¿Cómo podríamos mejorar KNN para conseguir mejores\n",
    "resultados?\n",
    "\n",
    "Podriamos aplicar one-hot-enconding para codificar los valores categóricos. Tambien\n",
    "estaria bien normalizar el resto de valores. Bien aplicando una resta de la normal y\n",
    "dividiendo por la desviación típica o bien haciendo que todos los datos esten entre 0 y 1.\n",
    "Esto haría que la distancia euclídea represente mejor al individuo.\n",
    "\n",
    "### Claves de la respuesta\n",
    "1. Jugar con la arquitectura del modelo, el factor de aprendizaje, asegurar normalización correcta, y usar regularización L2 para evitar sobreajustes.\n",
    "2. Si nos interesa sólo la precisión, usar Random Forest. Si queremos ver el proceso de decisión, usar Decision Tree.\n",
    "3. Usar one-hot-encoding y normalización.\n",
    "\n",
    "## Problema 2\n",
    "En un problema de Machine Learning, hemos utilizado la librería train_test_split para\n",
    "dividir el conjunto de entrenamiento y de test. En concreto se ha utilizado con los\n",
    "siguientes valores train_test_split(data, y, train_size = 0.8, random_state = 1)\n",
    "Sin embargo, haciendo pruebas vemos que en función del random_state o del tamaño\n",
    "de los datos de entrenamiento el resultado varia hasta un 5% de precisión.\n",
    "1. ¿Cómo podríamos abordar este problema?\n",
    "\n",
    "### Respuesta ChatGPT\n",
    "La variabilidad en los resultados del modelo de Machine Learning debido a la aleatoriedad en la división de los conjuntos de entrenamiento y prueba puede abordarse de varias maneras:\n",
    "\n",
    "1. **Fijar la Semilla (Random State):** Si deseas obtener resultados reproducibles, puedes fijar la semilla (random_state) a un valor específico. Esto garantiza que, cada vez que ejecutas el código, obtendrás la misma división de conjuntos de entrenamiento y prueba. Por ejemplo, `random_state = 1`.\n",
    "\n",
    "   ```python\n",
    "   train_test_split(data, y, train_size=0.8, random_state=1)\n",
    "   ```\n",
    "\n",
    "   Asegúrate de documentar y compartir la semilla utilizada para que otros puedan reproducir los resultados.\n",
    "\n",
    "2. **Validación Cruzada (Cross-Validation):** En lugar de depender de una sola división de entrenamiento/prueba, puedes utilizar técnicas de validación cruzada. K-Fold Cross-Validation implica dividir los datos en k particiones, entrenar y evaluar el modelo k veces, utilizando diferentes particiones como conjunto de prueba en cada iteración. Esto proporciona una evaluación más robusta del rendimiento del modelo.\n",
    "\n",
    "   ```python\n",
    "   from sklearn.model_selection import cross_val_score\n",
    "\n",
    "   scores = cross_val_score(model, data, y, cv=5)  # Ejemplo con k=5\n",
    "   ```\n",
    "\n",
    "3. **Ajuste del Tamaño del Conjunto de Entrenamiento:** El tamaño del conjunto de entrenamiento también puede influir en los resultados. Puedes experimentar con diferentes tamaños de conjunto de entrenamiento y evaluar cómo afecta al rendimiento. Asegúrate de tener suficientes datos en el conjunto de prueba para obtener una evaluación significativa del rendimiento del modelo.\n",
    "\n",
    "   ```python\n",
    "   train_test_split(data, y, train_size=0.7, random_state=1)  # Ejemplo con un 70% de entrenamiento\n",
    "   ```\n",
    "\n",
    "4. **Análisis Detallado:** Realizar un análisis detallado de por qué los resultados varían. Puede haber patrones particulares en los datos que se manifiesten solo en ciertas divisiones. Asegúrate de explorar las características de los datos y entender si hay algún sesgo o patrón que pueda explicar las diferencias en la precisión.\n",
    "\n",
    "Al implementar estas estrategias, puedes reducir la variabilidad en los resultados y obtener una evaluación más robusta del rendimiento del modelo.\n",
    "\n",
    "### Respuesta Isma\n",
    "La mejor forma de abordar este problema es usando cross validation. Con esta técnica\n",
    "calculamos el error medio entre diferentes particiones del dataset entre datos de\n",
    "entrenamiento y de validación, lo que minimiza la desviación que puede producir una\n",
    "mala partición del dataset entre entrenamiento y validación.\n",
    "\n",
    "### Claves de la respuesta\n",
    "Quiere que le expliques Cross-validation, ya que sirve precisamente para estos casos.\n",
    "\n",
    "## Pregunta 3\n",
    "Queremos detectar a partir de imágenes de rayos X si existe o no un tumor cerebral.\n",
    "Para ello disponemos de un dataset con 100.000 imágenes de 1024x1024 en escala de\n",
    "grises.\n",
    "\n",
    "1. Explica los pasos que harías para preparar los datos\n",
    "2. A priori, cual crees que sería el mejor modelo y porqué.\n",
    "3. Suponiendo que se han creado dos modelos y con 2000 datos de validación, el\n",
    "modelo A y el modelo B, ¿qué modelo elegirías?\n",
    "\n",
    "La matriz de confusión de A es:\n",
    "\n",
    "|          | Tumor | No-tumor |\n",
    "|----------|-------|----------|\n",
    "| **Tumor**   | 800   | 200      |\n",
    "| **No-tumor**| 100   | 900      |\n",
    "\n",
    "La matriz de confusión de B es:\n",
    "\n",
    "|          | Tumor | No-tumor |\n",
    "|----------|-------|----------|\n",
    "| **Tumor**   | 900   | 100      |\n",
    "| **No-tumor**| 200   | 800      |\n",
    "\n",
    "### Respuesta ChatGpt\n",
    "1. **Pasos para preparar los datos:**\n",
    "   - **Exploración de datos:** Analizar algunas imágenes para entender su formato y características. Verificar si hay desequilibrios en las clases.\n",
    "   - **Preprocesamiento:** Redimensionar las imágenes a un tamaño manejable, normalizar los valores de píxeles (escala de 0 a 1), y realizar cualquier ajuste necesario para mejorar la calidad de las imágenes.\n",
    "   - **Etiquetado:** Asignar etiquetas a las imágenes según la presencia o ausencia de un tumor cerebral.\n",
    "   - **División del conjunto de datos:** Separar los datos en conjuntos de entrenamiento, validación y prueba.\n",
    "   - **Data Augmentation (si es necesario):** Generar versiones adicionales de las imágenes mediante rotación, inversión, zoom, etc., para aumentar la variabilidad del conjunto de entrenamiento.\n",
    "   \n",
    "2. **Elección del mejor modelo:**\n",
    "   - Dada la naturaleza de las imágenes médicas, las redes neuronales convolucionales (CNN) son comúnmente utilizadas para tareas de clasificación de imágenes. Por lo tanto, un modelo de CNN sería una elección natural para este problema. Además, las CNN son eficientes para aprender patrones espaciales en imágenes.\n",
    "\n",
    "3. **Comparación de modelos A y B:**\n",
    "   - **Modelo A:**\n",
    "     - Verdaderos positivos (TP): 800\n",
    "     - Verdaderos negativos (TN): 900\n",
    "     - Falsos positivos (FP): 200\n",
    "     - Falsos negativos (FN): 100\n",
    "     - Precisión = (TP + TN) / (TP + TN + FP + FN) = (800 + 900) / (800 + 900 + 200 + 100) ≈ 0.86\n",
    "   - **Modelo B:**\n",
    "     - Verdaderos positivos (TP): 900\n",
    "     - Verdaderos negativos (TN): 800\n",
    "     - Falsos positivos (FP): 100\n",
    "     - Falsos negativos (FN): 200\n",
    "     - Precisión = (TP + TN) / (TP + TN + FP + FN) = (900 + 800) / (900 + 800 + 100 + 200) ≈ 0.85\n",
    "\n",
    "   Ambos modelos tienen una precisión similar, pero la elección entre ellos podría depender de otros factores como la sensibilidad (recall), la especificidad, el F1-score, etc. También, podrías considerar la interpretación clínica y los requisitos específicos del problema.\n",
    "\n",
    "### Respuesta Isma\n",
    "1. Explica los pasos que harías para preparar los datos\n",
    "\n",
    "Las imágenes son demasiado grandes habría que escalarlas a un tamaño más\n",
    "manejable, como por ejemplo 64x64. Podemos escalarlas a mano usando alguna\n",
    "algoritmos de escaldo, o podriamos intantar extraer las caracteristicas de una imagen\n",
    "como etapa de preprocesado inicial. Para ello podemos utilizar un Autoencoder o un\n",
    "algortimo de PCA. Por otro lado usando PCA dibujaría las diferentes clases para ver\n",
    "que pinta tiene. Tambien se podría hacer un análisis de las imágenes y detectar que\n",
    "pixeles aportan más información y hasta que punto podemos recortar las imágenes.\n",
    "\n",
    "2. A priori, cual crees que sería el mejor modelo y porqué.\n",
    "\n",
    "A priori el mejor modelo para procesar imágenes de los que hemos estudiado son las\n",
    "redes de neuronas convolucionales y los autoencoders. Tambien a priori el perceptrón\n",
    "multicapa se comporta mejor en este tipo de problemas que otros algoritmos. Pero no\n",
    "podemos asegurarlo a ciencia cierta hasta hacer pruebas.\n",
    "\n",
    "3. Suponiendo que se han creado dos modelos y con 2000 datos de validación, el\n",
    "modelo A y el modelo B, ¿qué modelo elegirías?\n",
    "\n",
    "El modelo B ya que es más importante que no haya falsos positivos, es decir que\n",
    "habiendo un tumor se clasifique como no tumor. Es peor este resultado que clasificar\n",
    "como tumor algo que no lo tiene, ya que normalmente se le realizaran otras pruebas\n",
    "antes de darle un diagnostico final.\n",
    "\n",
    "### Claves de la respuesta\n",
    "1. Las imagenes deben reducirse en tamaño y complejidad, ya sea reescalándolas de\n",
    "forma manual o usando convolución, autoencoders o PCA.\n",
    "2. Las redes neuronales convolucionales se especializan en imágenes.\n",
    "3. Este problema es serio y es muy importante detectar los positivos. \n",
    "Fallar en los negativos nos importa menos.\n",
    "\n",
    "## Problema 4\n",
    "Hemos conectado al videojuego Tetris un módulo que captura los eventos del mando,\n",
    "que se van registrando a la vez que se va haciendo una foto del estado del jugador. La\n",
    "idea es construir un sistema que permite jugar de forma autónoma a un agente que\n",
    "debe jugar igual que el jugador para el modo versus, donde un jugador juega contra\n",
    "una IA. Para ellos almacenamos en un histórico el estado del juego y la acción que ha\n",
    "realizado el jugador que puede ser una de las siguientes:\n",
    "\n",
    "- Mover Izquierda (MI)\n",
    "- Mover derecha (MD)\n",
    "- Rotar pieza (R)\n",
    "- Bajar pieza (B)\n",
    "- Guardar pieza (G)\n",
    "\n",
    "El estado está compuesto por una matriz con las celdas ocupadas por piezas, el nivel\n",
    "actual, la posición de la pieza que cae actualmente, la siguiente pieza y la pieza\n",
    "almacenada de repuesto.\n",
    "\n",
    "Si queremos utilizar KNN para seleccionar la acción más similar a la realizada por el\n",
    "usuario….\n",
    "\n",
    "1. ¿Como codificarías los datos para que KNN pueda funcionar correctamente y que\n",
    "medida de distancia usarías?\n",
    "2. Para saber si el agente imita correctamente al jugador, comprobamos que la\n",
    "secuencia de acciones realizadas por el agente sea similar a la del jugador para un\n",
    "estado de juego dado (El Tetris es determinista asumiendo la misma semilla\n",
    "aleatoria) De esta forma tendremos la secuencia de acciones MI|MD|R|B|MI|MI|B|G|MD|MI|MD|R|R|B.\n",
    "¿Qué medida de distancia utilizarías para calcular el error?\n",
    "\n",
    "### Respuesta ChatGPT\n",
    "1. **Codificación de Datos para KNN:**\n",
    "   - Cada estado del juego y acción realizada por el jugador debe ser codificado en un formato numérico para que KNN pueda operar. Puedes utilizar un enfoque de \"one-hot encoding\" para las acciones y convertir el estado del juego en un vector unidimensional, incluyendo todos los elementos relevantes (matriz de celdas ocupadas, nivel, posición de la pieza actual, siguiente pieza, pieza almacenada).\n",
    "\n",
    "   - Por ejemplo, si tienes cinco acciones posibles (MI, MD, R, B, G), podrías codificarlas como [1, 0, 0, 0, 0] para MI, [0, 1, 0, 0, 0] para MD, y así sucesivamente. Concatena esta representación con el vector que describe el estado del juego.\n",
    "\n",
    "   - Respecto a la medida de distancia, la elección de la distancia dependerá de la naturaleza de tus datos y la importancia relativa de cada característica. La distancia euclidiana es común, pero también podrías considerar otras métricas como la distancia de Manhattan o la distancia de Minkowski.\n",
    "\n",
    "2. **Medida de Distancia para Calcular el Error:**\n",
    "   - Dado que estás tratando con una secuencia de acciones, la distancia entre dos secuencias puede evaluarse mediante la distancia de edición (también conocida como distancia de Levenshtein). Esta medida cuenta el número mínimo de operaciones necesarias para transformar una secuencia en la otra, donde las operaciones son inserciones, eliminaciones o sustituciones de elementos.\n",
    "\n",
    "   - En tu caso, podrías usar la distancia de edición para comparar la secuencia de acciones realizadas por el jugador con la secuencia de acciones generadas por el agente. Cuanto menor sea la distancia de edición, más similares son las secuencias.\n",
    "\n",
    "   - La distancia de edición se adapta bien a comparaciones de secuencias y puede ser adecuada para evaluar el rendimiento del agente en términos de imitar la secuencia de acciones del jugador en un estado de juego dado.\n",
    "\n",
    "### Respuesta Isma\n",
    "1. ¿Como codificarías los datos para que KNN pueda funcionar correctamente y que\n",
    "medida de distancia usarías?\n",
    "\n",
    "- La cuadrícula con piezas seria una matriz de entrada donde valdría 1 la casilla X,Y\n",
    "esta ocupada por una pieza y 0 en caso contrario\n",
    "- La posición de la pieza actual se guardará como un valor real con el origen de\n",
    "coordinadas de (0,0) en la esquina inferior izquierda de la parte jugable y que ira\n",
    "de 0 a 1.\n",
    "- Usamos One-hot-encoding para guardar el identificador de la pieza guardada, la\n",
    "actual y la próxima ya que la categoria no es ordinal\n",
    "- Para saber el nivel tambien codificaremos este número como número real entre\n",
    "0-1 seindo 0 el nivel 0 y 1 el nivel más alto posible.\n",
    "- como medida de similitud usaría la distancia de Manhattan ya que en este tipo de\n",
    "problemas las diagonales no son importantes a priori (en el tetris no te puedes\n",
    "mover en diagonal)\n",
    "- Tendría una ventana temporal de acciones realizadas previamente ya que hay\n",
    "una dependencia entre las acciones realizadas anteriormente y las nuevas.\n",
    "\n",
    "2. Para saber si el agente imita correctamente al jugador, comprobamos que la\n",
    "secuencia de acciones realizadas por el agente sea similar a la del jugador para un\n",
    "estado de juego dado (El Tetris es determinista asumiendo la misma semilla\n",
    "aleatoria) De esta forma tendremos la secuencia de acciones MI|MD|R|B|MI|MI|B|G|MD|MI|MD|R|R|B.\n",
    "¿Qué medida de distancia utilizarías para calcular el error?\n",
    "\n",
    "Usaría distancia de edición. La similitud sería el número de cambios que hacen que\n",
    "una cadena sea igual que la otra. Esta medida es más representativa que una distancia\n",
    "euclídea, primero porque el valor de la clase no es ordinal y por otro lado, porque hay\n",
    "una dependencia temporal de las acciones realizadas. Si queremos imitar a la\n",
    "percepción el comportamiento del humano, debemos realizar las mismas acciones en\n",
    "le mismo orden más allá de que estas sean buenas o malas.\n",
    "\n",
    "### Claves de la respuesta\n",
    "1. Representar el estado con unos datos con sentido.\n",
    "2. Para cadenas y secuencias se usa la distancia de edición, también llamada distancia de Levenshtein.\n",
    "Mide el número de cambios que hay que hacer para convertir una instancia en otra (casa → cala → calla → calle)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
