{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79756688",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (5000,402) and (401,25) not aligned: 402 (dim 1) != 401 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 31\u001b[0m\n\u001b[0;32m     27\u001b[0m lambda_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     29\u001b[0m X_with_bias \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack([np\u001b[38;5;241m.\u001b[39mones((X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m)), X])\n\u001b[1;32m---> 31\u001b[0m annCost \u001b[38;5;241m=\u001b[39m cost(theta1, theta2, X_with_bias, Y, lambda_)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCost de la red neuronal: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mannCost\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     34\u001b[0m checkNNGradients(backprop, reg_param\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\Desktop\\AAMD\\Practica5\\ann.py:85\u001b[0m, in \u001b[0;36mcost\u001b[1;34m(theta1, theta2, X, y, lambda_)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;124;03mCompute cost for 2-layer neural network. \u001b[39;00m\n\u001b[0;32m     55\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     80\u001b[0m \n\u001b[0;32m     81\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     83\u001b[0m m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(y)\n\u001b[1;32m---> 85\u001b[0m predictions \u001b[38;5;241m=\u001b[39m predict(theta1, theta2, X)\n\u001b[0;32m     87\u001b[0m J \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m m) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39msum(y \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(predictions) \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m y) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m predictions))\n\u001b[0;32m     89\u001b[0m reg_term \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\Desktop\\AAMD\\Practica5\\ann.py:41\u001b[0m, in \u001b[0;36mpredict\u001b[1;34m(theta1, theta2, a1)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(theta1, theta2, a1):\n\u001b[0;32m     20\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;124;03m    Predict the label of an input given a trained neural network.\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03m        It has a length equal to the number of examples.\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m     a1, a2, a3 \u001b[38;5;241m=\u001b[39m feedForward(theta1, theta2, a1)\n\u001b[0;32m     43\u001b[0m     p \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(a3, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
      "File \u001b[1;32m~\\Desktop\\AAMD\\Practica5\\ann.py:10\u001b[0m, in \u001b[0;36mfeedForward\u001b[1;34m(theta1, theta2, a1)\u001b[0m\n\u001b[0;32m      6\u001b[0m a1s \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack([np\u001b[38;5;241m.\u001b[39mones((m, \u001b[38;5;241m1\u001b[39m)), a1])\n\u001b[0;32m      8\u001b[0m a1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcolumn_stack((np\u001b[38;5;241m.\u001b[39mones((a1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m)), a1))\n\u001b[1;32m---> 10\u001b[0m a2 \u001b[38;5;241m=\u001b[39m sig(np\u001b[38;5;241m.\u001b[39mdot(a1s, theta1\u001b[38;5;241m.\u001b[39mT))\n\u001b[0;32m     12\u001b[0m a2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack([np\u001b[38;5;241m.\u001b[39mones((m, \u001b[38;5;241m1\u001b[39m)), a1])\n\u001b[0;32m     14\u001b[0m a3 \u001b[38;5;241m=\u001b[39m sig(np\u001b[38;5;241m.\u001b[39mdot(a1, theta2\u001b[38;5;241m.\u001b[39mT))\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (5000,402) and (401,25) not aligned: 402 (dim 1) != 401 (dim 0)"
     ]
    }
   ],
   "source": [
    "from ann import cost, backprop\n",
    "from utils import checkNNGradients\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.io import loadmat, savemat\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#Ejercicio 1\n",
    "data = loadmat('data/ex3data1.mat', squeeze_me=True)\n",
    "y = data['y']\n",
    "X = data['X']\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False, categories='auto')\n",
    "\n",
    "# Y es una fila de 5000 entradas. El encoder busca el rango entre el mínimo y el máximo (10) y crea una matriz de 5000 x 10\n",
    "# en la que se pone a 1 la entrada correspondiente y 0 en las demás.\n",
    "# El reshape es para que la fila la trate como una matriz de tamaño 5000 x 1\n",
    "Y = encoder.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "weights = loadmat('data/ex3weights.mat')\n",
    "theta1, theta2 = weights['Theta1'], weights['Theta2']\n",
    "lambda_ = 1\n",
    "\n",
    "X_with_bias = np.hstack([np.ones((X.shape[0], 1)), X])\n",
    "\n",
    "annCost = cost(theta1, theta2, X_with_bias, Y, lambda_)\n",
    "print(f'Cost de la red neuronal: {annCost:.2f}%')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ba0d49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0779670e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d93923",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
